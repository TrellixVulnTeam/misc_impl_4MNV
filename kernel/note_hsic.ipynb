{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy case, \n",
    "\n",
    "$X\\sim N(\\mu,\\Sigma)$, $f(X)=[1,0]^T X+b$, $g(X)=BX+b$. Solve the following optimization problem \n",
    "\n",
    "$$ \\min_{B,a,b} \\text{HSIC}(f(X),g(X)) - (B - [1,0])^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from jaxkern import (\n",
    "    rbf_kernel, linear_kernel, estimate_sigma_median, hsic, mmd)\n",
    "\n",
    "import jax\n",
    "from jax.experimental import optimizers\n",
    "from jax import grad, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_kde(X):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6,6)\n",
    "    lim = np.min(X)-1, np.max(X)+1\n",
    "    XX,YY = np.meshgrid(\n",
    "        np.linspace(lim[0], lim[1], 100),\n",
    "        np.linspace(lim[0], lim[1], 100))\n",
    "    XY = np.vstack([XX.ravel(), YY.ravel()])\n",
    "    kernel = stats.gaussian_kde(X.T)\n",
    "    Z = kernel(XY).reshape(XX.shape)\n",
    "    # ax.scatter(X[:,0], X[:,1], c='k', s=3)\n",
    "    ax.imshow(Z, cmap='Blues',\n",
    "              extent=[lim[0], lim[1], lim[0], lim[1]])\n",
    "    ax.set_xlim([lim[0], lim[1]])\n",
    "    ax.set_ylim([lim[0], lim[1]])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "d = 2\n",
    "lr = .01\n",
    "num_steps = 100\n",
    "batch_size = 128\n",
    "\n",
    "npr.seed(0)\n",
    "mu  = np.array([0,0])\n",
    "cov = np.array([[1,0], [0,1]])\n",
    "Xdist = stats.multivariate_normal(mu, cov)\n",
    "X = Xdist.rvs(size=(n,))\n",
    "X = jax.device_put(X)\n",
    "\n",
    "sigma = estimate_sigma_median(X)\n",
    "gamma = 1/(2*(sigma**2))\n",
    "print(f'sigma={sigma}')\n",
    "print(f'gamma={gamma}')\n",
    "\n",
    "def kernel(X,Y):\n",
    "    return rbf_kernel(X,Y,gamma=gamma)\n",
    "\n",
    "A = jnp.array([[1,0]], dtype=jnp.float32)\n",
    "params = {\n",
    "    'B': jnp.array([[.5,.5]], dtype=jnp.float32),\n",
    "#     'a': random.normal(key, (1,)),\n",
    "#     'b': random.normal(key, (1,)),\n",
    "}\n",
    "\n",
    "def f(params, X):\n",
    "    return jnp.dot(A,X)\n",
    "def g(params, X):\n",
    "    return jnp.dot(params['B'],X)\n",
    "f = jax.vmap(f, (None, 0), 0)\n",
    "g = jax.vmap(g, (None, 0), 0)\n",
    "\n",
    "def loss_fn(params, X):\n",
    "    fX = f(params, X)\n",
    "    gX = g(params, X)\n",
    "    loss = hsic(fX, gX, kernel, kernel) + cosine_sim(A.T, params['B'].T) + jnp.linalg.norm(params['B'], ord=2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.sgd(lr)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for i in range(num_steps):\n",
    "    start_time = time.time()\n",
    "    params = get_params(opt_state)\n",
    "    \n",
    "    fX = f(params, X)\n",
    "    gX = g(params, X)\n",
    "    fgX = jnp.hstack([fX, gX])\n",
    "    \n",
    "    l = loss_fn(params, X)\n",
    "    grd = grad(loss_fn)(get_params(opt_state), X)\n",
    "    opt_state = opt_update(i, grd, opt_state)\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print(f'[{i:3}] time={epoch_time:4.4f}\\t loss={l:5.8f}\\t A^TB={jnp.dot(A,params[\"B\"].T)} B={params[\"B\"]}')\n",
    "        \n",
    "        plt.scatter(fgX[:,0], fgX[:,1], label=i)\n",
    "        plt.xlim((-5,5))\n",
    "        plt.ylim((-5,5))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "plt.legend()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foo = jnp.array([[1,2],[3,4]])\n",
    "fill_diagonal(foo, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = params['B']\n",
    "jax.numpy.linalg.norm(B-A, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
