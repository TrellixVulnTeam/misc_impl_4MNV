{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import scipy\n",
    "import numpy as onp\n",
    "onp.set_printoptions(precision=3,suppress=True)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "from jax import grad, jit, vmap, device_put, random\n",
    "from flax import linen as nn\n",
    "from jax.scipy.stats import dirichlet\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.patches as mpl_patches\n",
    "\n",
    "# https://matplotlib.org/3.1.1/gallery/style_sheets/style_sheets_reference.html\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 25\n",
    "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "cmap = plt.cm.get_cmap('bwr')\n",
    "\n",
    "from tabulate import tabulate\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "from setup_convgp import *\n",
    "from plt_utils import *\n",
    "from gpax import *\n",
    "from dataset import *\n",
    "\n",
    "jax_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ec9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_by_bbox = True\n",
    "dir_cub200 = './data/CUB_200_2011'\n",
    "dir_cub200_images = os.path.join(dir_cub200, 'images')\n",
    "\n",
    "if crop_by_bbox:\n",
    "    dir_train = os.path.join(dir_cub200, 'cropped_images_train')\n",
    "    dir_test  = os.path.join(dir_cub200, 'cropped_images_test')\n",
    "else:\n",
    "    dir_train = os.path.join(dir_cub200, 'images_train')\n",
    "    dir_test  = os.path.join(dir_cub200, 'images_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "def transform_normalize(im, mean, std):\n",
    "    \"\"\" Assumes `im` has dimension (H, W, C) with dtype of `np.uint8` \"\"\"\n",
    "    assert(im.ndim == 3)\n",
    "    mean = np.array(mean, dtype=np.float32)*255\n",
    "    std = np.array(std, dtype=np.float32)*255\n",
    "    im = im.astype(np.float32)\n",
    "    im = (im - mean) / std\n",
    "    return im\n",
    "\n",
    "\n",
    "def transform_normalize_undo(im, mean, std):\n",
    "    \"\"\" Un-normalize by `mean` & `std` but also  normalize \n",
    "        s.t. `im` has range of [0, 1] for visualization purposes \"\"\"\n",
    "    assert(im.ndim == 3)\n",
    "    mean = np.array(mean, dtype=np.float32)*255\n",
    "    std = np.array(std, dtype=np.float32)*255\n",
    "    im = im*std + mean\n",
    "    im = im/255\n",
    "    return im\n",
    "\n",
    "normalize = lambda im: transform_normalize(np.asarray(im), mean, std)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.RandomCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      normalize])\n",
    "transform_test = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     normalize])\n",
    "dataset_train = torchvision.datasets.ImageFolder(dir_train, transform_train)\n",
    "dataset_test = torchvision.datasets.ImageFolder(dir_test, transform_test)\n",
    "idx_to_class = {v:k for k,v in dataset_train.class_to_idx.items()}\n",
    "\n",
    "dataset_train, dataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7579cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, y = dataset_test[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.imshow(transform_normalize_undo(im, mean, std))\n",
    "ax.set_title(f'{idx_to_class[y]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3e6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cxr] *",
   "language": "python",
   "name": "conda-env-cxr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
