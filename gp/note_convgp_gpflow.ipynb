{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6382e0f6",
   "metadata": {},
   "source": [
    "goal\n",
    "- figure out convolutional gp impl in gpflow and convgp\n",
    "    - https://github.com/GPflow/GPflow/blob/develop/gpflow/kernels/convolutional.py\n",
    "    - https://github.com/GPflow/GPflow/blob/1e1de824397c828a47d9eca002251041296c91d4/gpflow/covariances/kufs.py\n",
    "        - Kuu,Kuf computes `K(Zpatch)` and `K(Zpatch, patches(X))`!\n",
    "        - Kuf: do averaging of patch-wise response afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from gpflow import set_trainable\n",
    "from gpflow.ci_utils import is_continuous_integration\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-4)\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "MAXITER = 2 if is_continuous_integration() else 100\n",
    "NUM_TRAIN_DATA = (\n",
    "    5 if is_continuous_integration() else 100\n",
    ")  # This is less than in the original rectangles dataset\n",
    "NUM_TEST_DATA = 7 if is_continuous_integration() else 300\n",
    "H = W = 14  # width and height. In the original paper this is 28\n",
    "IMAGE_SHAPE = [H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63320a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0 : x1 + 1] = 1\n",
    "\n",
    "\n",
    "def make_random_rectangle(arr):\n",
    "    x0 = np.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = np.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = np.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = np.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "\n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = np.zeros((num, h, w)), np.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return (\n",
    "        d.reshape(num, w * h).astype(gpflow.config.default_float()),\n",
    "        Y.astype(gpflow.config.default_float()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70758ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data = make_rectangles_dataset(NUM_TRAIN_DATA, *IMAGE_SHAPE)\n",
    "Xt, Yt = test_data = make_rectangles_dataset(NUM_TEST_DATA, *IMAGE_SHAPE)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(X[i, :].reshape(*IMAGE_SHAPE))\n",
    "    plt.title(Y[i, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2476b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_m = gpflow.models.SVGP(\n",
    "    gpflow.kernels.SquaredExponential(),\n",
    "    gpflow.likelihoods.Bernoulli(),\n",
    "    gpflow.inducing_variables.InducingPoints(X.copy()),\n",
    ")\n",
    "rbf_training_loss_closure = rbf_m.training_loss_closure(data, compile=True)\n",
    "rbf_elbo = lambda: -rbf_training_loss_closure().numpy()\n",
    "print(\"RBF elbo before training: %.4e\" % rbf_elbo())\n",
    "\n",
    "set_trainable(rbf_m.inducing_variable, False)\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    rbf_training_loss_closure,\n",
    "    variables=rbf_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER},\n",
    ")\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")\n",
    "\n",
    "train_acc = np.mean((rbf_m.predict_y(X)[0] > 0.5).numpy().astype(\"float\") == Y)\n",
    "test_acc = np.mean((rbf_m.predict_y(Xt)[0] > 0.5).numpy().astype(\"float\") == Yt)\n",
    "print(f\"Train acc: {train_acc * 100}%\\nTest acc : {test_acc*100}%\")\n",
    "print(\"RBF elbo after training: %.4e\" % rbf_elbo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839eada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f64 = lambda x: np.array(x, dtype=np.float64)\n",
    "positive_with_min = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4))(tfp.bijectors.Softplus())\n",
    "constrained = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4), scale=f64(100.0))(\n",
    "    tfp.bijectors.Sigmoid()\n",
    ")\n",
    "max_abs_1 = lambda: tfp.bijectors.AffineScalar(shift=f64(-2.0), scale=f64(4.0))(\n",
    "    tfp.bijectors.Sigmoid()\n",
    ")\n",
    "\n",
    "colour_channels = 1\n",
    "patch_shape = [3, 3]\n",
    "conv_k = gpflow.kernels.Convolutional(gpflow.kernels.SquaredExponential(), IMAGE_SHAPE, patch_shape)\n",
    "conv_k.base_kernel.lengthscales = gpflow.Parameter(1.0, transform=positive_with_min())\n",
    "# Weight scale and variance are non-identifiable. We also need to prevent variance from shooting off crazily.\n",
    "conv_k.base_kernel.variance = gpflow.Parameter(1.0, transform=constrained())\n",
    "conv_k.weights = gpflow.Parameter(conv_k.weights.numpy(), transform=max_abs_1())\n",
    "conv_f = gpflow.inducing_variables.InducingPatches(\n",
    "    np.unique(conv_k.get_patches(X).numpy().reshape(-1, 9), axis=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_k.image_shape)\n",
    "print(conv_k.patch_shape)\n",
    "print(conv_k.base_kernel)\n",
    "print(conv_k.colour_channels)\n",
    "print(conv_k.patch_len, conv_k.num_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ca953",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conv_k.get_patches(X).shape = TensorShape([100, 144, 9])\n",
    "image_shape = IMAGE_SHAPE\n",
    "patch_shape = patch_shape\n",
    "num_data = tf.shape(X)[0]\n",
    "print(X.shape)\n",
    "# (N, H*W)\n",
    "castX = tf.transpose(tf.reshape(X, [num_data, -1, colour_channels]), [0, 2, 1])\n",
    "print(castX.shape)\n",
    "# (N, 1, H*W)\n",
    "patches = tf.image.extract_patches(\n",
    "            # (N, H, W, 1)\n",
    "            tf.reshape(castX, [-1, image_shape[0], image_shape[1], 1], name=\"rX\"),\n",
    "            [1, patch_shape[0], patch_shape[1], 1],\n",
    "            [1, 1, 1, 1],\n",
    "            [1, 1, 1, 1],\n",
    "            \"VALID\")\n",
    "print(patches.shape)\n",
    "# (N, 12, 12, 9)\n",
    "shp = tf.shape(patches)  # img x out_rows x out_cols\n",
    "reshaped_patches = tf.reshape(\n",
    "    patches, [num_data, 1 * shp[1] * shp[2], shp[3]]\n",
    ")\n",
    "print(reshaped_patches.shape)\n",
    "# (N, n_patches_per_im, pH*pW) \n",
    "# (100, 144, 9)\n",
    "\n",
    "patch_uniq = np.unique(conv_k.get_patches(X).numpy().reshape(-1, 9), axis=0)\n",
    "print(patch_uniq.shape)\n",
    "# (45, 9)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(12,12,figsize=(10,10))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(patches[0,i,j,:].numpy().reshape((3,3)))\n",
    "        ax.set_xticks([]); ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5870da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_k.K\n",
    "# def K(self, X, X2=None):\n",
    "#     Xp = self.get_patches(X)  # [N, P, patch_len]\n",
    "#     Xp2 = Xp if X2 is None else self.get_patches(X2)\n",
    "#     bigK = self.base_kernel.K(Xp, Xp2)  # [N, num_patches, N, num_patches]\n",
    "#     W2 = self.weights[:, None] * self.weights[None, :]  # [P, P]\n",
    "#     W2bigK = bigK * W2[None, :, None, :]\n",
    "#     return tf.reduce_sum(W2bigK, [1, 3]) / self.num_patches ** 2.0\n",
    "self = conv_k\n",
    "X2 = X[:50]\n",
    "\n",
    "# len(X)=N, len(X2)=M\n",
    "Xp = self.get_patches(X)\n",
    "Xp2 = Xp if X2 is None else self.get_patches(X2)\n",
    "print('Xp', Xp.shape, Xp2.shape) # (N, num_patches, patch_len)\n",
    "bigK = self.base_kernel.K(Xp, Xp2)\n",
    "print('bigK', bigK.shape)   # [N, num_patches, M, num_patches]\n",
    "W2 = self.weights[:, None] * self.weights[None, :]  # [num_patches, num_patches]\n",
    "print('w^2', W2.shape) # (144, 144)\n",
    "W2bigK = bigK * W2[None, :, None, :] # [N, num_patches, M, num_patches]\n",
    "print('w^2*K', W2bigK.shape) # w^2*K (100, 144, 100, 144)\n",
    "print('K', W2bigK.shape, tf.math.reduce_min(W2bigK).numpy(), tf.math.reduce_max(W2bigK).numpy())\n",
    "K = tf.reduce_sum(W2bigK, [1, 3]) / self.num_patches ** 2.0\n",
    "print('K', K.shape, tf.math.reduce_min(K).numpy(), tf.math.reduce_max(K).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f784a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigKzx = self.base_kernel.K(conv_f.Z, Xp)\n",
    "K2 = tf.reduce_sum(bigKzx, [2])/self.num_patches\n",
    "K2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b24f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_m = gpflow.models.SVGP(conv_k, gpflow.likelihoods.Bernoulli(), conv_f)\n",
    "set_trainable(conv_m.inducing_variable, False)\n",
    "set_trainable(conv_m.kernel.base_kernel.variance, False)\n",
    "set_trainable(conv_m.kernel.weights, False)\n",
    "conv_training_loss_closure = conv_m.training_loss_closure(data, compile=True)\n",
    "conv_elbo = lambda: -conv_training_loss_closure().numpy()\n",
    "print(\"conv elbo before training: %.4e\" % conv_elbo())\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    conv_training_loss_closure,\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER / 10},\n",
    ")\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32188dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable(conv_m.kernel.base_kernel.variance, True)\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    conv_training_loss_closure,\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER},\n",
    ")\n",
    "train_acc = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype(\"float\") == Y)\n",
    "test_acc = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype(\"float\") == Yt)\n",
    "print(f\"Train acc: {train_acc * 100}%\\nTest acc : {test_acc*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_elbo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1de93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.print_summary(conv_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2c014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl]",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
