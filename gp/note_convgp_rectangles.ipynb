{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nuclear-danish",
   "metadata": {},
   "source": [
    "goal \n",
    "- implement convolutional GP\n",
    "    - interdomain inducing points in patch space\n",
    "    - rectangles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple, Union, List, Iterable\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CPP_VMODULE'] = '=bfc_allocator=1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, device_put, random\n",
    "from flax import linen as nn\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n",
    "print(jax.local_device_count())\n",
    "print(jax.devices())\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as onp\n",
    "onp.set_printoptions(precision=3,suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from setup_convgp import *\n",
    "from plt_utils import *\n",
    "from gpax import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0 : x1 + 1] = 1\n",
    "\n",
    "\n",
    "def make_random_rectangle(arr):\n",
    "    x0 = onp.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = onp.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = onp.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = onp.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "\n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = onp.zeros((num, h, w)), onp.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return (\n",
    "        d.reshape(num, w * h).astype(onp.float32),\n",
    "        Y.astype(onp.float32),\n",
    "    )\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "onp.random.seed(123)\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "MAXITER = 2 # 100\n",
    "NUM_TRAIN_DATA = 50 # 100\n",
    "NUM_TEST_DATA = 100 # 300\n",
    "H = W = 14  # width and height. In the original paper this is 28\n",
    "h = w = 14\n",
    "IMAGE_SHAPE = [H, W]\n",
    "\n",
    "\n",
    "X, Y = make_rectangles_dataset(NUM_TRAIN_DATA, *IMAGE_SHAPE)\n",
    "Xt, Yt = make_rectangles_dataset(NUM_TEST_DATA, *IMAGE_SHAPE)\n",
    "X, Y, Xt, Yt = np.array(X), np.array(Y), np.array(Xt), np.array(Yt)\n",
    "data = (X,Y); test_data = (Xt,  Yt)\n",
    "\n",
    "\n",
    "print(X.shape, Y.shape, type(X))\n",
    "print(Xt.shape, Yt.shape)\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(16, 6))\n",
    "for i in range(4):\n",
    "    ax = axs[i]\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(X[i, :].reshape(*IMAGE_SHAPE), cmap='Greys')\n",
    "    ax.set_title(Y[i, 0], fontsize=(25))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a52a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "    output_dim: int = 2\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *IMAGE_SHAPE, 1)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.output_dim)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x\n",
    "    \n",
    "class CNNTrunk(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *IMAGE_SHAPE, 1)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        return x\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    y_onehot = jax.nn.one_hot(labels, num_classes=output_dim).squeeze()\n",
    "    return -np.mean(np.sum(y_onehot * logits, axis=-1))\n",
    "\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits, labels)\n",
    "    pred = np.argmax(logits, -1).reshape(-1,1)\n",
    "    accuracy = np.mean(pred == labels)\n",
    "    metrics = {'loss': loss,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(opt, batch, key):\n",
    "    key, subkey = random.split(key)\n",
    "    X, y = batch\n",
    "    def loss_fn(params):\n",
    "        logits = CNN(output_dim=output_dim).apply(params, X)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grad = grad_fn(opt.target)\n",
    "    opt = opt.apply_gradient(grad)\n",
    "    metrics = compute_metrics(logits, y)\n",
    "    log = {'loss': loss,\n",
    "           'accuracy': metrics['accuracy'],\n",
    "           'dense0_kernel_gradnorm': linalg.norm(grad['params']['Dense_0']['kernel'])}\n",
    "    return opt, log, key\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(params, X):\n",
    "    logits = CNN(output_dim=output_dim).apply(params, X)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def eval_model(params, data_test, logit_fn=eval_step):\n",
    "    test_n_batches, test_batches = get_data_stream(\n",
    "        random.PRNGKey(0), 100, data_test)\n",
    "\n",
    "    logits = []; labels = []\n",
    "    for _ in range(test_n_batches):\n",
    "        batch = next(test_batches)\n",
    "        X, y = batch\n",
    "        logit = logit_fn(params, X)\n",
    "        labels.append(y.reshape(-1, 1))\n",
    "        logits.append(logit)\n",
    "\n",
    "    logits = np.vstack(logits)\n",
    "    labels = np.vstack(labels)\n",
    "    metrics = compute_metrics(logits, labels)\n",
    "    metrics = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33484d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN(output_dim=output_dim)\n",
    "params = model.init(key, np.ones((1,28,28,1)))\n",
    "opt = flax_create_optimizer(params, 'Adam', {'learning_rate': .03})\n",
    "\n",
    "metrics = eval_model(params, test_data)\n",
    "print(f'[{0:3}] test \\t'\n",
    "      f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "      f'accuracy={metrics[\"accuracy\"]:.3f}\\t')\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "bsz = 64\n",
    "train_n_batches, train_batches = get_data_stream(key, bsz, data)\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    logs = defaultdict(list)\n",
    "    for it in range(train_n_batches):\n",
    "        step = epoch*train_n_batches+it\n",
    "        batch = next(train_batches)\n",
    "        opt, log, key = train_step(opt, batch, key)\n",
    "        params = opt.target\n",
    "        for k, v in log.items():\n",
    "            logs[k].append(v)\n",
    "        if step%(train_n_batches)==0:\n",
    "            avg_metrics = {k: np.mean(np.array(v))\n",
    "                           for k, v in logs.items()}\n",
    "            print(f'[{epoch:3}|{100*it/train_n_batches:5.2f}%]\\t'\n",
    "                  f'Loss={avg_metrics[\"loss\"]:.3f}\\t'\n",
    "                  f'accuracy={avg_metrics[\"accuracy\"]:.3f}\\t')\n",
    "    \n",
    "    metrics = eval_model(params, test_data)\n",
    "    print(f'[{epoch:3}] test \\t'\n",
    "          f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "          f'accuracy={metrics[\"accuracy\"]:.3f}\\t')\n",
    "    \n",
    "    \n",
    "cnn_save_path = f'./cnn_params_rectangle.pkl'\n",
    "pytree_save(opt.target, cnn_save_path)\n",
    "params = pytree_load(CNN(output_dim=output_dim).init(key, np.ones((1,28,28,1))), cnn_save_path)\n",
    "\n",
    "metrics = eval_model(params, test_data)\n",
    "print(f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "      f'accuracy={metrics[\"accuracy\"]:.3f}\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41781f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_base = copy.deepcopy(get_config_base())\n",
    "config = ml_collections.ConfigDict(config_base)\n",
    "config.image_shape = (14, 14, 1)\n",
    "config.patch_shape = (3, 3)\n",
    "config.patch_encoder = None\n",
    "config.T_type = 'transl'\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shape = config.patch_shape \n",
    "image_shape = config.image_shape\n",
    "n_inducing = config.n_inducing\n",
    "output_dim = config.output_dim\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "model_cls = get_model_cls(key, config, X)\n",
    "model = model_cls()\n",
    "params = model.get_init_params(model, key, X_shape=config.image_shape)\n",
    "print(model)\n",
    "pytree_keys(params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-cooper",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "output_dim = 2\n",
    "lik_type = 'LikMulticlassDirichlet' # LikMulticlassDirichlet, LikMulticlassSoftmax, LikMultipleNormalKron\n",
    "α_ϵ = 1; α_δ = 10; n_mc_samples = 20\n",
    "image_shape = (14,14,1)\n",
    "patch_shape = (10,10)\n",
    "inducing_patch=True\n",
    "n_inducing = 20\n",
    "T_type = 'transl+isot_scal' # '', 'transl', 'isot_scal'\n",
    "use_loc_kernel = True\n",
    "patch_encoder = 'CNNMnist' # None, 'CNNMnist'\n",
    "\n",
    "\n",
    "init_val_m = gamma_to_lognormal(np.array([1.]))[0] \\\n",
    "    if lik_type == 'LikMulticlassDirichlet' else np.array([0.5])\n",
    "mean_fn_cls = partial(MeanConstant, output_dim=output_dim, init_val_m=init_val_m, flat=False)\n",
    "if lik_type == 'LikMulticlassDirichlet':\n",
    "    lik_cls = partial(LikMulticlassDirichlet, output_dim=output_dim, init_val_α_ϵ=α_ϵ, init_val_α_δ=α_δ, n_mc_samples=n_mc_samples)\n",
    "elif lik_type == 'LikMulticlassSoftmax':\n",
    "    lik_cls = partial(LikMulticlassSoftmax, output_dim=output_dim, n_mc_samples=n_mc_samples)\n",
    "else:\n",
    "    lik_cls = partial(LikMultipleNormalKron, output_dim=output_dim)\n",
    "\n",
    "\n",
    "kl_cls = CovSE if use_loc_kernel else partial(CovConstant, output_scaling=False)\n",
    "available_encoders = CovPatchEncoder.get_available_encoders()\n",
    "\n",
    "if patch_encoder not in available_encoders:\n",
    "    g_cls = LayerIdentity\n",
    "    kg_cls = partial(CovPatch, image_shape=image_shape, patch_shape=patch_shape, kp_cls=CovSE, kl_cls=kl_cls)\n",
    "else:\n",
    "    g_cls = available_encoders[patch_encoder]\n",
    "    XL_init_fn = partial(g_cls.get_XL, image_shape=image_shape)\n",
    "    kg_cls = partial(CovPatchEncoder, encoder=patch_encoder, XL_init_fn=XL_init_fn, kp_cls=CovSE, kl_cls=kl_cls)\n",
    "\n",
    "kx_cls = partial(CovConvolutional, kg_cls=kg_cls, inducing_patch=inducing_patch)\n",
    "k_cls = partial(CovMultipleOutputIndependent, output_dim=output_dim, k_cls=kx_cls, g_cls=g_cls)\n",
    "if T_type == '':\n",
    "    transform_cls = LayerIdentity\n",
    "else:\n",
    "    scal = np.array(patch_shape)/np.array(image_shape[:2])\n",
    "    A_init_val = trans2x3_from_scal_transl(scal,(0,0))\n",
    "    T_init_fn = lambda k, s: np.tile(np.array([BijSigmoid([np.mean(scal)*.5,np.mean(scal)*1.5]).reverse(np.mean(scal)*1.4), 0, 0.]),\n",
    "                                     (n_inducing, 1)) # (s, tx, ty)\n",
    "    bound_init_fn = partial(spatial_transform_bound_init_fn, in_shape=image_shape, out_shape=patch_shape)\n",
    "    transform_cls = partial(SpatialTransform, shape=patch_shape, n_transforms=n_inducing, \n",
    "                            T_type=T_type, T_init_fn=T_init_fn, A_init_val=A_init_val, output_transform=use_loc_kernel,\n",
    "                            bound_init_fn=bound_init_fn)\n",
    "\n",
    "if inducing_patch:\n",
    "#     Xu_initial = get_init_patches(key, X, n_inducing, image_shape, patch_shape)\n",
    "    Xu_initial = np.take(X, random.randint(key, (n_inducing,), 0, len(X)), axis=0)\n",
    "    Xu_initial = Xu_initial.reshape((-1, *image_shape))\n",
    "    inducing_loc_cls = partial(InducingLocations,\n",
    "                               shape=Xu_initial.shape,\n",
    "                               init_fn=lambda k,s: Xu_initial,\n",
    "                               transform_cls=transform_cls)\n",
    "else:\n",
    "    Xu_initial = X[np.linspace(0,len(X)-1,n_inducing).astype(np.int32)].copy()\n",
    "    inducing_loc_cls = partial(InducingLocations,\n",
    "                               shape=Xu_initial.shape,\n",
    "                               init_fn=lambda k,s: Xu_initial)\n",
    "\n",
    "print('Xu:', Xu_initial.shape)\n",
    "\n",
    "model = SVGP(mean_fn_cls=mean_fn_cls,\n",
    "             k_cls=k_cls,\n",
    "             lik_cls=lik_cls,\n",
    "             inducing_loc_cls=inducing_loc_cls,\n",
    "             n_data=len(X),\n",
    "             output_dim=output_dim)\n",
    "\n",
    "\n",
    "params = model.get_init_params(model, key, X_shape=image_shape)\n",
    "print(model)\n",
    "pytree_keys(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained weights & set initial values\n",
    "# if g_cls != LayerIdentity:\n",
    "#     cnn_save_path = f'./rectangle_cnn_params.pkl'\n",
    "#     encoder_params = pytree_load({'params': params['params']['k']['g']}, cnn_save_path)\n",
    "#     encoder_params_kvs = pytree_get_kvs(encoder_params)\n",
    "#     params = pytree_mutate(params, {f'params/k/g/{k}': v for k,v in encoder_params_kvs.items()})\n",
    "\n",
    "kwd_notrain =  ['mean_fn', 'Xu/X']\n",
    "kwd_notrain += [f'params/k/ks_{i}/kl/σ2' for i in range(config.output_dim)]\n",
    "kwd_notrain += [f'params/k/ks_{i}/kg/kl/σ2' for i in range(config.output_dim)]\n",
    "kwd_trainslow = [] #  # 'Xu/transform'\n",
    "opt = flax_create_multioptimizer(\n",
    "    params, 'Adam',\n",
    "    [{'learning_rate': 0.}, {'learning_rate': .03}, {'learning_rate': .1}],\n",
    "    [lambda p, v: pytree_path_contains_keywords(p, kwd_notrain),\n",
    "     lambda p, v: pytree_path_contains_keywords(p, kwd_trainslow),\n",
    "     lambda p, v: not pytree_path_contains_keywords(p, kwd_notrain+kwd_trainslow)])\n",
    "\n",
    "flax_check_multiopt(params, opt)\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if isinstance(transform_cls(), SpatialTransform):\n",
    "    ind = np.arange(n_inducing)\n",
    "    \n",
    "    m = model.bind(params)\n",
    "    A = m.Xu.transform.T\n",
    "    S = pytree_leaf(params, 'params/Xu/X')\n",
    "    A = A[ind]; S = S[ind]\n",
    "\n",
    "    fn = vmap(spatial_transform_details, (0, 0, None), 0)\n",
    "    T, Gs = fn(A, S, patch_shape)\n",
    "    fig, axs = plt.subplots(2, len(A), figsize=(3*len(A),3*2))\n",
    "    for i in range(len(T)):\n",
    "        plt_spatial_transform(axs[:,i], Gs[i], S[i], T[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a488d46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "import time\n",
    "        \n",
    "@jax.jit\n",
    "def eval_model(params, data):\n",
    "    Xt, Yt = data\n",
    "    Xt = Xt.reshape((len(Xt), *image_shape))\n",
    "    Ey, Vy = model.apply(params, Xt, method=model.pred_y, rngs={'lik_mc_samples': key})\n",
    "    pred = np.argmax(Ey, -1).reshape(-1, 1)\n",
    "    acc = np.mean(pred == Yt)\n",
    "    return acc\n",
    "\n",
    "@jax.jit\n",
    "def train_step2(step, opt, batch, key):\n",
    "    key, subkey = random.split(key)\n",
    "    Xb, yb = batch\n",
    "    Xb = Xb.reshape((len(Xb), *image_shape))\n",
    "    y_onehot = jax.nn.one_hot(yb.squeeze(), num_classes=output_dim).reshape((-1,output_dim))\n",
    "    def loss_fn(params):\n",
    "        fx = model.apply(params,\n",
    "                         (Xb, y_onehot),\n",
    "                         method=model.mll,\n",
    "                         rngs={'lik_mc_samples': subkey})\n",
    "        return -fx, {}\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    params = opt.target\n",
    "    (loss, aux), grad = grad_fn(params)\n",
    "    opt = opt.apply_gradient(flax_params2model(model, grad))\n",
    "    log = {'loss': loss}\n",
    "    return opt, log, key\n",
    "\n",
    "\n",
    "bsz = 5\n",
    "train_n_batches, train_batches = get_data_stream(key, bsz, data)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    for it in range(train_n_batches):\n",
    "        step = epoch*train_n_batches+it\n",
    "        batch = next(train_batches)\n",
    "        opt, log, key = train_step2(step, opt, batch, key)\n",
    "        params = opt.target\n",
    "        if step%(train_n_batches*n_epochs//30)==0:\n",
    "            insert_str = '/kg' if isinstance(model.k_cls().k_cls(), CovConvolutional) else ''\n",
    "            log.update({\n",
    "               'k.ls': jax.nn.softplus(pytree_leaf(params, f'params/k/kx/ls')\n",
    "                                       if isinstance(model.k_cls(), CovICM) else \n",
    "                                       np.hstack([pytree_leaf(params, f'params/k/ks_{i}{insert_str}/kp/ls')\n",
    "                                                  for i in range(output_dim)])),\n",
    "               'k.σ2': jax.nn.softplus(pytree_leaf(params, f'params/k/kx/σ2')\n",
    "                                       if isinstance(model.k_cls(), CovICM) else \n",
    "                                       np.hstack([pytree_leaf(params, f'params/k/ks_{i}{insert_str}/kp/σ2')\n",
    "                                                  for i in range(output_dim)])),\n",
    "               'kl.ℓ': jax.nn.softplus(np.hstack([pytree_leaf(params, f'params/k/ks_{i}/kg/kl/ls')\n",
    "                                                  for i in range(output_dim)])\n",
    "                                       if  isinstance(model.k_cls(), CovMultipleOutputIndependent) and \\\n",
    "                                           not isinstance(model.k_cls().k_cls().kg_cls().kl_cls(), CovConstant) else np.array([np.nan]))})\n",
    "            acc = eval_model(params, data)\n",
    "            acc_test = eval_model(params, test_data)\n",
    "            print(f'[{epoch:3}|{100*it/train_n_batches:5.2f}%]\\t'\n",
    "                  f'Time={time.time()-start:.3f}\\t'\n",
    "                  f'Loss={log[\"loss\"]:.3f}\\t'\n",
    "                  f'k.ls={log[\"k.ls\"][:3]}\\t'\n",
    "                  f'k.σ2={log[\"k.σ2\"][:3]}\\t'\n",
    "                  f'kl.ℓ = {log[\"kl.ℓ\"][:3]}\\t'\n",
    "                  f'acc={acc:.3f}|{acc_test:.3f}\\t')\n",
    "            start = time.time()\n",
    "\n",
    "\n",
    "params = opt.target\n",
    "\n",
    "\n",
    "# N=100\n",
    "# CovSE(g_cls=CNNTrunk(pretrained=True)): .96 (bsz=5, n_inducing=50%)\n",
    "# CovSE: .65\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=False): .89 (bsz=5, n_inducing=60%)\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=True):  .90 (bsz=5, n_inducing=45 all unique patches)\n",
    "\n",
    "# N=20\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=False): .85/.65 (bsz=5, n_inducing=100%)\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=True):  1.0/.99 (bsz=5, n_inducing=100%, lr=.1)\n",
    "\n",
    "# if use location kernel=CovSE helps with bad perf of optimiznig for Xu/T\n",
    "# N=50\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=False): .9/.68     (bsz=5,  n_inducing=20)\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=True): 0.960|0.810 (bsz=5,  n_inducing=20, Xu/X,Xu/T fixed)\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=True): 1.000|0.930 (bsz=5,  n_inducing=20, Xu/X fixed, Xu/T opt)\n",
    "#     - 0.740|0.640 another run ...\n",
    "# CovConvolutional(g_cls=CovSE, patch_inducing_loc=True, kl_cls=CovSE): 0.980|0.920 (bsz=5,  n_inducing=20, Xu/X fixed, Xu/T opt)\n",
    "\n",
    "\n",
    "# patch_shape (10, 10)\n",
    "# patch_encoder=LayerIdentity    acc=0.800|0.660\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if isinstance(transform_cls(), SpatialTransform):\n",
    "    ind = np.arange(n_inducing)\n",
    "    \n",
    "    m = model.bind(params)\n",
    "    A = m.Xu.transform.T\n",
    "    S = pytree_leaf(params, 'params/Xu/X')\n",
    "    A = A[ind]; S = S[ind]\n",
    "\n",
    "    fn = vmap(spatial_transform_details, (0, 0, None), 0)\n",
    "    T, Gs = fn(A, S, patch_shape)\n",
    "    fig, axs = plt.subplots(2, len(A), figsize=(3*len(A),3*2))\n",
    "    for i in range(len(T)):\n",
    "        plt_spatial_transform(axs[:,i], Gs[i], S[i], T[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inducing locations\n",
    "digits = ['-','|']\n",
    "\n",
    "if config.inducing_patch:\n",
    "    Xu, transl = inducing_loc_cls().apply({'params': pytree_leaf(params, 'params/Xu')})\n",
    "else:\n",
    "    Xu = inducing_loc_cls().apply({'params': pytree_leaf(params, 'params/Xu')})\n",
    "\n",
    "\n",
    "qm = pytree_leaf(params, 'params/q/μ')\n",
    "M = len(Xu)\n",
    "    \n",
    "\n",
    "gridspec_kw = {'width_ratios': np.ones((output_dim,)), 'height_ratios': [3,1]}\n",
    "fig, axs = plt.subplots(2,output_dim,figsize=(output_dim*8,8))\n",
    "n_top = config.n_inducing\n",
    "c = 0; ind = np.argsort(qm[c,:])\n",
    "ylim = (np.min(qm)-.5, np.max(qm)+.5)\n",
    "\n",
    "for c in range(config.output_dim):\n",
    "    ind = np.argsort(qm[c,:])[::-1]\n",
    "    # variational μ\n",
    "    ax = axs[0,c]\n",
    "    for co in range(config.output_dim):\n",
    "        ls = '--' if co != c else '-'\n",
    "        ax.plot(np.arange(n_inducing), qm[co,ind], ls, label=f'{digits[co]}')\n",
    "    ax.set_title(f'qμ ({digits[c]})', fontsize=35)\n",
    "    ax.grid()\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.legend(fontsize=20)\n",
    "    \n",
    "    # top weighted patches\n",
    "    ax = axs[1,c]\n",
    "    ims = Xu[ind].reshape((-1,*patch_shape))[:n_top]\n",
    "    grid = make_im_grid(ims, im_per_row=min(len(ims), 10))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(grid, cmap='Greys', vmin=0, vmax=1)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4203ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cxr] *",
   "language": "python",
   "name": "conda-env-cxr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
