{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "#     gpflow: https://gpflow.readthedocs.io/en/master/notebooks/advanced/gps_for_big_data.html\n",
    "#             https://github.com/GPflow/GPflow/blob/develop/gpflow/models/sgpr.py#L263\n",
    "#     julia:  https://github.com/STOR-i/GaussianProcesses.jl/blob/master/src/sparse/fully_indep_train_conditional.jl\n",
    "#     ladax:  https://github.com/danieljtait/ladax\n",
    "#\n",
    "\n",
    "import sys\n",
    "sys.path.append('../kernel')\n",
    "\n",
    "import numpy as onp\n",
    "import numpy.random as npr\n",
    "onp.set_printoptions(precision=3,suppress=True)\n",
    "\n",
    "import jax\n",
    "from jax import device_put, random\n",
    "import jax.numpy as np\n",
    "import jax.numpy.linalg as linalg\n",
    "from jax.scipy.linalg import cho_solve, solve_triangular\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax import optim, struct\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import torch\n",
    "print(torch.cuda.is_available(), jax.devices())\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# https://matplotlib.org/3.1.1/gallery/style_sheets/style_sheets_reference.html\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 25\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "cmap = plt.cm.get_cmap('bwr')\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import sys\n",
    "sys.path.append('../kernel')\n",
    "from jaxkern import (cov_se, cov_rq, cov_pe, LookupKernel, normalize_K, mtgp_k)\n",
    "\n",
    "from plt_utils import plt_savefig, plt_scaled_colobar_ax\n",
    "from gp import gp_regression_chol, run_sgd\n",
    "from gpax import is_psd, cholesky_jitter\n",
    "from gpax import softplus_inv, BijectiveSoftplus, BijectiveFillTril, BijectiveExp, BijectiveSoftplusFillTril\n",
    "from gpax import log_func_default, log_func_simple, flax_run_optim, filter_contains, flax_get_optimizer\n",
    "from gpax import CovSE, LikNormal, GPR, GPRFITC, VFE, VariationalMultivariateNormal\n",
    "from gpax import kl_mvn, kl_mvn_tril, kl_mvn_tril_zero_mean_prior, vgp_qf_tril\n",
    "from gpax import flax_create_optimizer, get_data_stream, diag_indices_kth, rand_μΣ, pytree_mutate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters \n",
    "\n",
    "xlim = (-1, 1)\n",
    "ylim = (-2, 2)\n",
    "n_train = 200\n",
    "n_test = 200\n",
    "σn = .5\n",
    "logsn = np.log(σn)\n",
    "lr = .01\n",
    "num_steps = 20\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "def f_gen(x):\n",
    "    return np.sin(x * 3 * 3.14) + \\\n",
    "           0.3 * np.cos(x * 9 * 3.14) + \\\n",
    "           0.5 * np.sin(x * 7 * 3.14)\n",
    "\n",
    "## Plotting\n",
    "\n",
    "npr.seed(0)\n",
    "key = jax.random.PRNGKey(0)\n",
    "X_train = np.expand_dims(npr.uniform(xlim[0], xlim[1], size=n_train), 1)\n",
    "y_train = f_gen(X_train) + σn * npr.rand(n_train, 1)\n",
    "data = (X_train, y_train)\n",
    "X_test  = np.expand_dims(np.linspace(*xlim, n_test), 1)\n",
    "\n",
    "X_train = device_put(X_train)\n",
    "y_train = device_put(y_train)\n",
    "X_test = device_put(X_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "ax.plot(X_train, y_train, 'x', alpha=1)\n",
    "ax.grid()\n",
    "ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-narrative",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class SVGP(nn.Module):\n",
    "    data: Tuple[np.ndarray, np.ndarray]\n",
    "    n_inducing: int\n",
    "    n_data: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.k = CovSE()\n",
    "        self.lik = LikNormal()\n",
    "        X, y = self.data\n",
    "        init_fn = lambda k,s: X[:self.n_inducing]\n",
    "        self.Xu = self.param('Xu', init_fn, \n",
    "                             (self.n_inducing, X.shape[-1]))\n",
    "        self.q = VariationalMultivariateNormal(np.eye(len(self.Xu)))\n",
    "\n",
    "    def get_init_params(self, key):\n",
    "        Xs = np.ones((1, self.data[0].shape[-1]))\n",
    "        ys = np.ones((1, self.data[1].shape[-1]))\n",
    "        params = self.init(key, (Xs, ys), method=self.mll)\n",
    "        return params\n",
    "\n",
    "    def mll(self, data):\n",
    "        X, y = data\n",
    "        k = self.k\n",
    "        m = self.n_inducing\n",
    "        Xu, μq, Lq = self.Xu, self.q.μ, self.q.L\n",
    "\n",
    "        Kss = k(X, full_cov=False)\n",
    "        Kus = k(Xu, X)\n",
    "        Kuu = k(Xu, Xu)\n",
    "        Luu = cholesky_jitter(Kuu, jitter=1e-6)\n",
    "\n",
    "        μqf, σ2qf = vgp_qf_tril(Kss, Kus, Luu, μq, Lq, full_cov=False)\n",
    "        elbo_lik = self.lik.variational_expectation(y, μqf, σ2qf)\n",
    "        elbo_nkl = -kl_mvn_tril_zero_mean_prior(μq, Lq, Luu)\n",
    "        \n",
    "        α = self.n_data/len(X) \\\n",
    "            if self.n_data is not None else 1.\n",
    "        elbo = α*elbo_lik + elbo_nkl\n",
    "        return elbo\n",
    "\n",
    "    def pred_f(self, Xs, full_cov=False):\n",
    "        k = self.k\n",
    "        m = self.n_inducing\n",
    "        Xu, μq, Lq = self.Xu, self.q.μ, self.q.L\n",
    "\n",
    "        Kss = k(Xs, full_cov=full_cov)\n",
    "        Kus = k(Xu, Xs)\n",
    "        Kuu = k(Xu, Xu)\n",
    "        Luu = cholesky_jitter(Kuu, jitter=1e-6)\n",
    "\n",
    "        μf, Σf = vgp_qf_tril(Kss, Kus, Luu, μq, Lq, full_cov=full_cov)\n",
    "        return μf, Σf\n",
    "\n",
    "    def pred_y(self, Xs):\n",
    "        μf, Σf = self.pred_f(Xs)\n",
    "        ns = len(Σf)\n",
    "        μy, Σy = μf, Σf + self.lik.σ2*np.diag(np.ones((ns,)))\n",
    "        return μy, Σy\n",
    "\n",
    "\n",
    "n_inducing=5\n",
    "key = jax.random.PRNGKey(0)\n",
    "model = SVGP(data, n_inducing, n_data=n_train)\n",
    "params = model.get_init_params(jax.random.PRNGKey(0))\n",
    "bsz = 20\n",
    "Xs, ys = X_test[:bsz], X_test[:bsz]\n",
    "datas = (Xs, ys)\n",
    "elbo = model.apply(params, datas, method=model.mll)\n",
    "\n",
    "\n",
    "params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-tragedy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsz = 20\n",
    "bsz = 100\n",
    "optimizer_kwargs = {'learning_rate': .001}\n",
    "num_steps = 1000\n",
    "n_inducing = 50\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(20,30), sharey=True)\n",
    "\n",
    "def get_model(i):\n",
    "    if i == 0:\n",
    "        return 'GPR', GPR(data)\n",
    "    if i == 1:\n",
    "        return f'GPR+FITC (m={n_inducing})', GPRFITC(data, n_inducing)\n",
    "    if i == 2:\n",
    "        return f'GPR+VFE (m={n_inducing})', VFE(data, n_inducing)\n",
    "    if i == 3:\n",
    "        return f'SVGP (m={n_inducing})', SVGP(data, n_inducing, n_train)\n",
    "    \n",
    "    \n",
    "def log_func(i, f, params):\n",
    "    if i%20==0:\n",
    "        print(f'[{i:3}]\\tLoss={f(params):.3f}\\t'\n",
    "              f'lik.σn={jax.nn.softplus(params[\"params\"][\"lik\"][\"σ2\"][0]):.3f}\\t'\n",
    "              f'k.ℓ={jax.nn.softplus(params[\"params\"][\"k\"][\"ℓ\"][0]):.3f}\\t'\n",
    "              f'k.σ2={jax.nn.softplus(params[\"params\"][\"k\"][\"σ2\"][0]):.3f}\\t'\n",
    "              + (f'Xu[:2]={params[\"params\"][\"Xu\"][:2,0]}' if 'Xu' in params[\"params\"] else ''))\n",
    "\n",
    "# log_func = lambda i, f, params: log_func_default(i, f, params, 1) \n",
    "\n",
    "n_batches, batches = get_data_stream(\n",
    "    key, bsz, X_train, y_train)\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    name, model = get_model(i)\n",
    "    params = model.get_init_params(key)\n",
    "    if i != 0:\n",
    "        Xu_initial = params['params']['Xu']\n",
    "    \n",
    "    if i < 3:\n",
    "        continue\n",
    "        nmll = lambda params: -model.apply(params, method=model.mll)\n",
    "        nmll = jax.jit(nmll)\n",
    "        params = flax_run_optim(nmll, params, num_steps=num_steps, log_func=log_func,\n",
    "                                optimizer_kwargs=optimizer_kwargs)\n",
    "        mll = model.apply(params, method=model.mll)\n",
    "    else:\n",
    "        ######################################################\n",
    "        params = pytree_mutate(params, {'params/lik/σ2': softplus_inv(np.array([0.022])),\n",
    "                                        'params/k/σ2': softplus_inv(np.array([0.040])),\n",
    "                                        'params/k/ℓ': softplus_inv(np.array([0.097]))})\n",
    "\n",
    "        @jax.jit\n",
    "        def train_step(step, opt, batch):\n",
    "            def f(params):\n",
    "                return -model.apply(params, batch, method=model.mll)\n",
    "            fg_fn = jax.value_and_grad(f)\n",
    "            fx, grad = fg_fn(opt.target)\n",
    "            opt = opt.apply_gradient(grad)\n",
    "            log = {'step': step,\n",
    "                   'loss': fx,\n",
    "                   'lik.σ2': jax.nn.softplus(opt.target[\"params\"][\"lik\"][\"σ2\"][0]),\n",
    "                   'k.ℓ': jax.nn.softplus(opt.target[\"params\"][\"k\"][\"ℓ\"][0]),\n",
    "                   'k.σ2': jax.nn.softplus(opt.target[\"params\"][\"k\"][\"σ2\"][0])}\n",
    "            return opt, log\n",
    "\n",
    "        opt = flax_create_optimizer(params, 'Adam', {'learning_rate': .002})\n",
    "        for j in range(num_steps):\n",
    "            for k in range(n_batches):\n",
    "                step = j*n_batches+k\n",
    "                batch = next(batches)\n",
    "                opt, log = train_step(step, opt, batch)\n",
    "                if step%(20*n_batches)==0:\n",
    "                    print(f'[{log[\"step\"]:3}]\\t'\n",
    "                          f'Loss={log[\"loss\"]:.3f}\\t'\n",
    "                          f'lik.σ2={log[\"lik.σ2\"]:.3f}\\t'\n",
    "                          f'k.ℓ={log[\"k.ℓ\"]:.3f}\\t'\n",
    "                          f'k.σ2={log[\"k.σ2\"]:.3f}\\t')\n",
    "\n",
    "        params = opt.target\n",
    "        mll = model.apply(params, data, method=model.mll)\n",
    "\n",
    "\n",
    "    μ, Σ = model.apply(params, X_test, method=model.pred_y)\n",
    "    std = np.expand_dims(np.sqrt(np.diag(Σ)), 1)\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.plot(X_test, μ, color='k')\n",
    "    ax.fill_between(X_test.squeeze(), (μ-2*std).squeeze(), (μ+2*std).squeeze(), alpha=.2, color=cmap(0))\n",
    "    ax.scatter(X_train, y_train, marker='x', color='r', s=50, alpha=.4)\n",
    "    if i != 0:\n",
    "        Xu = params['params']['Xu']\n",
    "        ax.plot(Xu_initial, np.ones_like(Xu)*ylim[1]-.04, \"k|\", mew=2, label=\"Inducing locations\")\n",
    "        ax.plot(Xu, np.ones_like(Xu)*ylim[0]+.04, \"k|\", mew=2, label=\"Inducing locations\")\n",
    "    ax.grid()\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_title(f'{name}: {\"mll\" if i <3 else \"elbo\"}={-mll:.2f}')\n",
    "    \n",
    "\n",
    "fig.tight_layout()\n",
    "# plt_savefig(fig, 'summary/assets/plt_apx_comparison.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-characteristic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "q = VariationalMultivariateNormal(np.ones((50,50)))\n",
    "mvn = q.apply({'params': params['params']['q']})\n",
    "# params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, model = get_model(3)\n",
    "model.apply(params, batch, method=model.mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-fleece",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
