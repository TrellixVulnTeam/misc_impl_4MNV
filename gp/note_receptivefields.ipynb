{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "going-skating",
   "metadata": {},
   "source": [
    "goal\n",
    "- conv architecture for bagnet using 1x1 convolution. \n",
    "    - verify receptive field computation etc.\n",
    "- implement functions to draw bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CPP_VMODULE'] = '=bfc_allocator=1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random, vjp, vmap\n",
    "from flax import linen as nn\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpl_patches\n",
    "\n",
    "from gpax import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9deef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchsize = 10\n",
    "h,w = 28,28\n",
    "image = np.arange(0,h*w).reshape((1,1,h,w))\n",
    "_, c, x, y = image.shape\n",
    "padded_image = np.zeros((c, x + patchsize - 1, y + patchsize - 1))\n",
    "ind = jax.ops.index[:, (patchsize-1)//2:(patchsize-1)//2 + x, (patchsize-1)//2:(patchsize-1)//2 + y]\n",
    "padded_image = jax.ops.index_update(padded_image, ind, image[0])\n",
    "\n",
    "plt.imshow(padded_image.transpose((1,2,0)))\n",
    "# image = padded_image[None].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-strand",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    # rf: [46, 46]\n",
    "    #\n",
    "    def __init__(self,\n",
    "                 num_classes=1,\n",
    "                 n_filters=16):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        def _make_block(in_channels, out_channels, stride=2, padding=1):\n",
    "            return [nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=4, stride=stride, padding=padding),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.ReLU()]\n",
    "        n_layers = 4\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.extend(_make_block(\n",
    "                1 if i == 0 else n_filters*(2**(i-1)), n_filters*(2**i)))\n",
    "        self.conv_blocks = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, output_feat=True):\n",
    "        # (1,224,224)\n",
    "        x = self.conv_blocks(x)\n",
    "#         # (128,14,14)\n",
    "        return x\n",
    "\n",
    "\n",
    "def cnn16(pretrained=False, **kwargs):\n",
    "    if pretrained:\n",
    "        raise ValueError('No pretrained model for CNN')\n",
    "    kwargs['n_filters'] = 16\n",
    "    model = CNN(**kwargs)\n",
    "    return model\n",
    "\n",
    "def compute_RF_numerical(net,img_np, out_cnn_idx=None):\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                m.bias.data.fill_(0)\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.fill_(0)\n",
    "            m.eval()\n",
    "    \n",
    "    net.apply(weights_init)\n",
    "    img_ = torch.from_numpy(onp.array(img_np)).float()\n",
    "    img_.requires_grad = True\n",
    "    out_cnn=net(img_)\n",
    "    if out_cnn_idx is not None:\n",
    "        out_cnn = out_cnn[out_cnn_idx]\n",
    "    out_shape=out_cnn.size()\n",
    "    print('out_shape: ', out_shape)\n",
    "    ndims=len(out_cnn.size())\n",
    "    grad=torch.zeros(out_cnn.size())\n",
    "    l_tmp=[]\n",
    "    for i in range(ndims):\n",
    "        if i==0 or i ==1:#batch or channel\n",
    "            l_tmp.append(0)\n",
    "        else:\n",
    "            l_tmp.append(out_shape[i]//2)\n",
    "    l_tmp = tuple(int(x) for x in l_tmp)\n",
    "    grad[l_tmp]=1\n",
    "    out_cnn.backward(gradient=grad)\n",
    "    grad_np=img_.grad[0,0].data.numpy()\n",
    "    idx_nonzeros=np.where(grad_np!=0)\n",
    "    RF=[np.max(idx)-np.min(idx)+1 for idx in idx_nonzeros]\n",
    "\n",
    "    return RF, grad_np\n",
    "\n",
    "\n",
    "\n",
    "model = cnn16(); h, w = 224, 224\n",
    "\n",
    "img_np = np.ones((1, 1, h, w))\n",
    "rf, gx = compute_RF_numerical(model, img_np)\n",
    "print(rf)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.imshow(gx.squeeze(), cmap='Greys')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-bandwidth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bagnet import bagnet33\n",
    "\n",
    "model = bagnet33(); model.eval()\n",
    "h, w = 224, 224\n",
    "img_np = np.arange(3*h*w).reshape((1, 3, h, w))/(3*h*w)\n",
    "rf, gx = compute_RF_numerical(model, img_np, out_cnn_idx=1)\n",
    "print(rf)\n",
    "print(gx.shape)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "ax = axs[0]\n",
    "ax.imshow(img_np[0].transpose((1,2,0)))\n",
    "\n",
    "ax = axs[1]\n",
    "gx[gx!=0] = 1\n",
    "ax.imshow(gx.squeeze(), cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-applicant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random, vjp, vmap\n",
    "from flax import linen as nn\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "\n",
    "def compute_receptive_fields(model_def, in_shape, spike_loc=None):\n",
    "    \"\"\"Computes receptive fields using gradients\n",
    "        For images, returns receptive fields for (h, w)\n",
    "    \"\"\"\n",
    "    x = np.ones(in_shape)\n",
    "    model = model_def()\n",
    "    params = model.init(random.PRNGKey(0), x)\n",
    "    params = freeze(jax.tree_map(lambda w: np.ones(w.shape),\n",
    "                                 unfreeze(params)))\n",
    "    # vjp (𝑥,𝑣)↦∂𝑓(𝑥)ᵀv\n",
    "    # vjp :: (a -> b) -> a -> (b, CT b -> CT a)\n",
    "    #     vjp: (f, x) -> (f(x), vjp_fn) where vjp_fn: u -> v\n",
    "    f = lambda x: model.apply(params, x)\n",
    "    y, vjp_fn = vjp(f, x)\n",
    "    S = y.shape\n",
    "    gy = np.zeros(S)\n",
    "    if spike_loc is not None:\n",
    "        ind = jax.ops.index[0, spike_loc[:,0], spike_loc[:,1], ...]\n",
    "    else:\n",
    "        ind = jax.ops.index[0, S[1]//2, S[2]//2, ...]\n",
    "    gy = jax.ops.index_update(gy, ind, 1)\n",
    "    gx = vjp_fn(gy)[0]\n",
    "    I = np.where(gx!=0)\n",
    "    rf = np.array([np.max(idx)-np.min(idx)+1\n",
    "                   for idx in I])[np.array([1,2])] # (y, x)\n",
    "    return rf, gx, gy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class CNNCxrTrunk(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        conv = partial(nn.Conv, kernel_size=(4, 4), strides=(2, 2))\n",
    "        # (1, 224, 224, 1)\n",
    "        x = conv(features=16)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=32)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=64)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "model_def = CNNMnistTrunk; h, w = 10+2, 10+2;  h, w = 28,28\n",
    "# model_def = CNNCxrTrunk; h, w = 46+2,46+2    # h, w = 224,224\n",
    "in_shape = (1, h, w, 1)\n",
    "# spike_loc = np.array([[1, 1], [1, -2], [-2, 1], [-2, -2]])\n",
    "spike_loc = np.array([[1, 1]])\n",
    "rf, gx, gy = compute_receptive_fields(model_def, in_shape)\n",
    "# _, gx, _ = compute_receptive_fields(model_def, in_shape, spike_loc)\n",
    "# gx = jax.ops.index_update(gx, gx!=0, 1)\n",
    "print(f'y.shape: {gy.shape} (spike_loc={(gy.shape[1]//2, gy.shape[2]//2)})')\n",
    "print('rf: ', rf)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.imshow(np.log(gx.squeeze()), cmap='Greys')\n",
    "r = rf//2\n",
    "xy = (h//2-r[1]-.5, w//2-r[0]-.5) # half-pixel\n",
    "rect = mpl_patches.Rectangle(xy, rf[1], rf[0],\n",
    "    linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74daa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CPP_VMODULE'] = '=bfc_allocator=1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random, vjp, vmap\n",
    "from flax import linen as nn\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpl_patches\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random, vjp, vmap\n",
    "from flax import linen as nn\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "from gpax import *\n",
    "\n",
    "\n",
    "class CNNcxr(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        conv = partial(nn.Conv, kernel_size=(4, 4), strides=(2, 2))\n",
    "        # (1, 224, 224, 1)\n",
    "        x = conv(features=16)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=32)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=64)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = conv(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        return x\n",
    "\n",
    "from gpax import *\n",
    "\n",
    "\n",
    "\n",
    "g_cls = CNNMnistTrunk; image_shape = (28, 28, 1)\n",
    "# g_cls = CNNMnistTrunk; image_shape = (14, 14, 1)\n",
    "# g_cls = CNNcxr; image_shape = (224, 224, 1)\n",
    "in_shape = (1, *image_shape)\n",
    "\n",
    "ind_start, rf = compute_receptive_fields_start_ind_extrap(\n",
    "    g_cls, (1, *image_shape))\n",
    "# rf, gx, gy = compute_receptive_fields(g_cls, in_shape)\n",
    "print(rf)\n",
    "print(gx.shape, gy.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.imshow(np.zeros(image_shape), cmap='Greys', origin='upper')\n",
    "ax.scatter(ind_start[:,0], ind_start[:,1])\n",
    "ax.grid()\n",
    "ax.set_title(rf)\n",
    "\n",
    "print(ind_start.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cls = CNNMnistTrunk; image_shape = (28, 28, 1)\n",
    "ind_start, rf = compute_receptive_fields_start_ind(\n",
    "    g_cls, (1, *image_shape))\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.imshow(np.zeros(image_shape), cmap='Greys', origin='upper')\n",
    "ax.scatter(ind_start[:,0], ind_start[:,1])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = (1,46,46,1)\n",
    "x = np.ones(in_shape)\n",
    "model = model_def()\n",
    "key = random.PRNGKey(0)\n",
    "params = model.init(key, x)\n",
    "print(model.apply(params, x).shape)\n",
    "\n",
    "spike_loc = np.array([[1, 1]])\n",
    "_, gx = compute_receptive_fields(model_def, in_shape, spike_loc)\n",
    "gx = jax.ops.index_update(gx, gx!=0, 1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.imshow(gx.squeeze(), cmap='Greys')\n",
    "ax.grid()\n",
    "# r = rf//2\n",
    "# xy = (h//2-r[1]-.5, w//2-r[0]-.5) # half-pixel\n",
    "# rect = mpl_patches.Rectangle(xy, rf[1], rf[0],\n",
    "#     linewidth=1, edgecolor='r', facecolor='none')\n",
    "# ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "gx.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cxr] *",
   "language": "python",
   "name": "conda-env-cxr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
