{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reference:\n",
    "#    https://peterroelants.github.io/posts/gaussian-process-kernels/\n",
    "#    https://distill.pub/2019/visual-exploration-gaussian-processes/\n",
    "#    http://gregorygundersen.com/blog/2019/06/27/gp-regression/\n",
    "#\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, det, cholesky\n",
    "from numpy.linalg import solve as backsolve\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, device_put\n",
    "import jax.numpy as jnp\n",
    "import jax.numpy.linalg as jnp_linalg\n",
    "from jax.experimental import optimizers\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# https://matplotlib.org/3.1.1/gallery/style_sheets/style_sheets_reference.html\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 25\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "cmap = plt.cm.get_cmap('bwr')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../kernel')\n",
    "from jaxkern import (rbf_kernel, linear_kernel, cov_se, cov_rq, cov_pe, cdist_sqeuclidean)\n",
    "\n",
    "from plt_utils import plt_savefig, plt_scaled_colobar_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gp_regression(X, y, Xt, k, σn):\n",
    "    n = len(X)\n",
    "    K  = k(X, X)+(σn**2)*np.eye(n)\n",
    "    Km = k(X, Xt)\n",
    "    Kt = k(Xt, Xt)\n",
    "    Kinv = inv(K)\n",
    "    μ = Km.T@Kinv@y_train\n",
    "    Σ = Kt - Km.T@Kinv@Km\n",
    "    logml = -(1/2)*y.T@Kinv@y - (1/2)*np.log(det(K)) - (n/2)*np.log(2*np.pi)\n",
    "    return μ, Σ, logml\n",
    "\n",
    "def gp_regression_chol(X, y, Xt, k, σn):\n",
    "    n = len(X)\n",
    "    K  = k(X, X)+(σn**2)*jnp.eye(n)\n",
    "    Km = k(X, Xt)\n",
    "    Kt = k(Xt, Xt)\n",
    "    L = jnp_linalg.cholesky(K)\n",
    "    α = jnp_linalg.solve(L.T, jnp_linalg.solve(L, y))\n",
    "    μ = Km.T@α\n",
    "    v = jnp_linalg.inv(L)@Km\n",
    "    Σ = Kt - v.T@v\n",
    "    logml = -(1/2)*y.T@α - jnp.sum(jnp.log(jnp.diag(L))) - (n/2)*jnp.log(2*jnp.pi)\n",
    "    return μ, Σ, logml[0,0]\n",
    "\n",
    "## Parameters \n",
    "\n",
    "xlim = (-2, 2)\n",
    "ylim = (-3, 3)\n",
    "n_train = 3\n",
    "n_test = 100\n",
    "σn = .1\n",
    "ℓ = 1\n",
    "ℓs = [.1, .3, 1]\n",
    "train_sizes = [3, 5, 10]\n",
    "lr = .002\n",
    "num_steps = 10\n",
    "\n",
    "def f_gen(x):\n",
    "    return np.sin(x)+np.sin(x*5)+np.cos(x*3)\n",
    "\n",
    "## Plotting\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, sharey=True)\n",
    "fig.set_size_inches(30, 15)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_test = np.expand_dims(np.linspace(*xlim, n_test), 1)\n",
    "X_train_all = np.expand_dims(\n",
    "    np.random.uniform(xlim[0], xlim[1], size=np.max(train_sizes)), 1)\n",
    "ϵ_all = σn*np.random.rand(np.max(train_sizes), 1)\n",
    "\n",
    "for i, ℓ in enumerate(ℓs):\n",
    "    for j, n_train in enumerate(train_sizes):\n",
    "        \n",
    "        X_train = X_train_all[:n_train]\n",
    "        ϵ = ϵ_all[:n_train]\n",
    "        y_train = f_gen(X_train) + ϵ\n",
    "        \n",
    "        if i == 1:\n",
    "            jX_train, jy_train, jX_test = device_put(X_train), device_put(y_train), device_put(X_test)\n",
    "            def gpse_nll(params):\n",
    "                k = lambda X, Y: cov_se(X, Y, ℓ=params['ℓ'])\n",
    "                μ, Σ, logml = gp_regression_chol(jX_train, jy_train, jX_test, k, σn)\n",
    "                return -logml\n",
    "            gpse_nll = jit(gpse_nll)\n",
    "            gpse_nll_grad = jit(grad(gpse_nll, argnums=0))\n",
    "            params = {'ℓ': jnp.ones(1)}\n",
    "            opt_init, opt_update, get_params = optimizers.sgd(lr)\n",
    "            opt_state = opt_init(params)\n",
    "            itercount = itertools.count()\n",
    "            for _ in range(num_steps):\n",
    "                params = get_params(opt_state)\n",
    "                params_grad = gpse_nll_grad(params)\n",
    "                opt_state = opt_update(next(itercount),params_grad, opt_state)\n",
    "            ℓ = params['ℓ'][0]\n",
    "        else:\n",
    "            ℓ = ℓs[i]\n",
    "\n",
    "        k = lambda X, Y: cov_se(X, Y, ℓ=ℓ)\n",
    "        μ, Σ, logml = gp_regression_chol(X_train, y_train, X_test, k, σn)\n",
    "        std = np.expand_dims(np.sqrt(np.diag(Σ)), 1)\n",
    "\n",
    "        ax = axs[i, j]\n",
    "        ax.plot(X_test, μ, color='k')\n",
    "        ax.fill_between(X_test.squeeze(), (μ-2*std).squeeze(), (μ+2*std).squeeze(), alpha=.2, color=cmap(.3))\n",
    "        ax.scatter(X_train, y_train, marker='x', color='r', s=50)\n",
    "        ax.grid()\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_title('$n=$'+f'{n_train}'+', $-\\log p(\\mathbf{y}\\mid X)$'+f'={-logml:.2f}')\n",
    "        \n",
    "        if j == 0 or i == 1:\n",
    "            ax.set_ylabel('$K_{SE}$'+f'(ℓ={ℓ:.2f})')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt_savefig(fig, 'summary/assets/plt_gp_regression_vary_trainsize.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
