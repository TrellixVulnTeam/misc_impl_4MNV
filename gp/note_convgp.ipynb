{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nuclear-danish",
   "metadata": {},
   "source": [
    "goal \n",
    "- implement convolutional GP\n",
    "    - interdomain inducing points in patch space\n",
    "    - rectangles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n",
      "1\n",
      "[GpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CPP_VMODULE'] = '=bfc_allocator=1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "os.environ['LD_LIBRARY_PATH'] = '${LD_LIBRARY_PATH}:/usr/local/cuda/lib64'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, device_put, random\n",
    "from flax import linen as nn\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n",
    "print(jax.local_device_count())\n",
    "print(jax.devices())\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as onp\n",
    "onp.set_printoptions(precision=3,suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from plt_utils import *\n",
    "from gpax import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "crazy-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 196) (10, 1) <class 'jax.interpreters.xla.DeviceArray'>\n",
      "(10, 196) (10, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0 : x1 + 1] = 1\n",
    "\n",
    "\n",
    "def make_random_rectangle(arr):\n",
    "    x0 = onp.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = onp.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = onp.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = onp.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "\n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = onp.zeros((num, h, w)), onp.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return (\n",
    "        d.reshape(num, w * h).astype(onp.float32),\n",
    "        Y.astype(onp.float32),\n",
    "    )\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "onp.random.seed(123)\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "MAXITER = 2 # 100\n",
    "NUM_TRAIN_DATA = 10 # 100\n",
    "NUM_TEST_DATA = 10 # 300\n",
    "H = W = 14  # width and height. In the original paper this is 28\n",
    "h = w = 14\n",
    "IMAGE_SHAPE = [H, W]\n",
    "\n",
    "\n",
    "X, Y = make_rectangles_dataset(NUM_TRAIN_DATA, *IMAGE_SHAPE)\n",
    "Xt, Yt = make_rectangles_dataset(NUM_TEST_DATA, *IMAGE_SHAPE)\n",
    "X, Y, Xt, Yt = np.array(X), np.array(Y), np.array(Xt), np.array(Yt)\n",
    "data = (X,Y); test_data = (Xt,  Yt)\n",
    "\n",
    "\n",
    "print(X.shape, Y.shape, type(X))\n",
    "print(Xt.shape, Yt.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(X[i, :].reshape(*IMAGE_SHAPE))\n",
    "    plt.title(Y[i, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320dfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "    output_dim: int = 2\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *IMAGE_SHAPE, 1)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.output_dim)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x\n",
    "    \n",
    "class CNNTrunk(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *IMAGE_SHAPE, 1)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    y_onehot = jax.nn.one_hot(labels, num_classes=output_dim).squeeze()\n",
    "    return -np.mean(np.sum(y_onehot * logits, axis=-1))\n",
    "\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits, labels)\n",
    "    pred = np.argmax(logits, -1).reshape(-1,1)\n",
    "    accuracy = np.mean(pred == labels)\n",
    "    metrics = {'loss': loss,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(opt, batch, key):\n",
    "    key, subkey = random.split(key)\n",
    "    X, y = batch\n",
    "    def loss_fn(params):\n",
    "        logits = CNN(output_dim=output_dim).apply(params, X)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grad = grad_fn(opt.target)\n",
    "    opt = opt.apply_gradient(grad)\n",
    "    metrics = compute_metrics(logits, y)\n",
    "    log = {'loss': loss,\n",
    "           'accuracy': metrics['accuracy'],\n",
    "           'dense0_kernel_gradnorm': linalg.norm(grad['params']['Dense_0']['kernel'])}\n",
    "    return opt, log, key\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(params, X):\n",
    "    logits = CNN(output_dim=output_dim).apply(params, X)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def eval_model(params, data_test, logit_fn=eval_step):\n",
    "    test_n_batches, test_batches = get_data_stream(\n",
    "        random.PRNGKey(0), 100, data_test)\n",
    "\n",
    "    logits = []; labels = []\n",
    "    for _ in range(test_n_batches):\n",
    "        batch = next(test_batches)\n",
    "        X, y = batch\n",
    "        logit = logit_fn(params, X)\n",
    "        labels.append(y.reshape(-1, 1))\n",
    "        logits.append(logit)\n",
    "\n",
    "    logits = np.vstack(logits)\n",
    "    labels = np.vstack(labels)\n",
    "    metrics = compute_metrics(logits, labels)\n",
    "    metrics = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d74b474f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] test \tLoss=0.687\taccuracy=0.610\t\n",
      "[  0| 0.00%]\tLoss=0.686\taccuracy=0.625\t\n",
      "[  0] test \tLoss=1.187\taccuracy=0.460\t\n",
      "[  1| 0.00%]\tLoss=1.289\taccuracy=0.406\t\n",
      "[  1] test \tLoss=0.694\taccuracy=0.520\t\n",
      "[  2| 0.00%]\tLoss=0.669\taccuracy=0.562\t\n",
      "[  2] test \tLoss=0.683\taccuracy=0.520\t\n",
      "[  3| 0.00%]\tLoss=0.641\taccuracy=0.578\t\n",
      "[  3] test \tLoss=0.707\taccuracy=0.520\t\n",
      "[  4| 0.00%]\tLoss=0.647\taccuracy=0.531\t\n",
      "[  4] test \tLoss=0.660\taccuracy=0.520\t\n",
      "[  5| 0.00%]\tLoss=0.608\taccuracy=0.562\t\n",
      "[  5] test \tLoss=0.628\taccuracy=0.720\t\n",
      "[  6| 0.00%]\tLoss=0.507\taccuracy=0.797\t\n",
      "[  6] test \tLoss=0.492\taccuracy=0.830\t\n",
      "[  7| 0.00%]\tLoss=0.338\taccuracy=0.875\t\n",
      "[  7] test \tLoss=0.358\taccuracy=0.830\t\n",
      "[  8| 0.00%]\tLoss=0.266\taccuracy=0.875\t\n",
      "[  8] test \tLoss=0.621\taccuracy=0.740\t\n",
      "[  9| 0.00%]\tLoss=0.197\taccuracy=0.938\t\n",
      "[  9] test \tLoss=0.583\taccuracy=0.780\t\n",
      "[ 10| 0.00%]\tLoss=0.439\taccuracy=0.844\t\n",
      "[ 10] test \tLoss=0.906\taccuracy=0.730\t\n",
      "[ 11| 0.00%]\tLoss=0.206\taccuracy=0.922\t\n",
      "[ 11] test \tLoss=0.231\taccuracy=0.910\t\n",
      "[ 12| 0.00%]\tLoss=0.044\taccuracy=1.000\t\n",
      "[ 12] test \tLoss=0.276\taccuracy=0.890\t\n",
      "[ 13| 0.00%]\tLoss=0.266\taccuracy=0.891\t\n",
      "[ 13] test \tLoss=0.211\taccuracy=0.940\t\n",
      "[ 14| 0.00%]\tLoss=0.138\taccuracy=0.922\t\n",
      "[ 14] test \tLoss=0.193\taccuracy=0.930\t\n",
      "[ 15| 0.00%]\tLoss=0.064\taccuracy=0.969\t\n",
      "[ 15] test \tLoss=0.332\taccuracy=0.920\t\n",
      "[ 16| 0.00%]\tLoss=0.067\taccuracy=0.969\t\n",
      "[ 16] test \tLoss=0.365\taccuracy=0.890\t\n",
      "[ 17| 0.00%]\tLoss=0.040\taccuracy=1.000\t\n",
      "[ 17] test \tLoss=0.292\taccuracy=0.900\t\n",
      "[ 18| 0.00%]\tLoss=0.028\taccuracy=1.000\t\n",
      "[ 18] test \tLoss=0.217\taccuracy=0.940\t\n",
      "[ 19| 0.00%]\tLoss=0.013\taccuracy=1.000\t\n",
      "[ 19] test \tLoss=0.278\taccuracy=0.940\t\n",
      "Loss=0.278\taccuracy=0.940\t\n"
     ]
    }
   ],
   "source": [
    "model = CNN(output_dim=output_dim)\n",
    "params = model.init(key, np.ones((1,28,28,1)))\n",
    "opt = flax_create_optimizer(params, 'Adam', {'learning_rate': .03})\n",
    "\n",
    "metrics = eval_model(params, test_data)\n",
    "print(f'[{0:3}] test \\t'\n",
    "      f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "      f'accuracy={metrics[\"accuracy\"]:.3f}\\t')\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "bsz = 64\n",
    "train_n_batches, train_batches = get_data_stream(key, bsz, data)\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    logs = defaultdict(list)\n",
    "    for it in range(train_n_batches):\n",
    "        step = epoch*train_n_batches+it\n",
    "        batch = next(train_batches)\n",
    "        opt, log, key = train_step(opt, batch, key)\n",
    "        params = opt.target\n",
    "        for k, v in log.items():\n",
    "            logs[k].append(v)\n",
    "        if step%(train_n_batches)==0:\n",
    "            avg_metrics = {k: np.mean(np.array(v))\n",
    "                           for k, v in logs.items()}\n",
    "            print(f'[{epoch:3}|{100*it/train_n_batches:5.2f}%]\\t'\n",
    "                  f'Loss={avg_metrics[\"loss\"]:.3f}\\t'\n",
    "                  f'accuracy={avg_metrics[\"accuracy\"]:.3f}\\t')\n",
    "    \n",
    "    metrics = eval_model(params, test_data)\n",
    "    print(f'[{epoch:3}] test \\t'\n",
    "          f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "          f'accuracy={metrics[\"accuracy\"]:.3f}\\t')\n",
    "    \n",
    "    \n",
    "cnn_save_path = f'./cnn_params_rectangle.pkl'\n",
    "pytree_save(opt.target, cnn_save_path)\n",
    "params = pytree_load(CNN(output_dim=output_dim).init(key, np.ones((1,28,28,1))), cnn_save_path)\n",
    "\n",
    "metrics = eval_model(params, test_data)\n",
    "print(f'Loss={metrics[\"loss\"]:.3f}\\t'\n",
    "      f'accuracy={metrics[\"accuracy\"]:.3f}\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prompt-cooper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({'params': {'mean_fn': {'c': DeviceArray([0.5, 0.5], dtype=float32)}, 'k': {'ks_0': {'kg': {'ls': DeviceArray([0.541], dtype=float32), 'σ2': DeviceArray([0.541], dtype=float32)}}, 'ks_1': {'kg': {'ls': DeviceArray([0.541], dtype=float32), 'σ2': DeviceArray([0.541], dtype=float32)}}}, 'Xu': {'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, 'q': {'μ': DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "             [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), 'L': DeviceArray([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "              0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "              0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "             [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "              0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "              0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)}}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = 2\n",
    "α_ϵ = 1; α_δ = 10; n_mc_samples = 20; n_inducing = 10\n",
    "patch_size = (3,3)\n",
    "\n",
    "lik_type = 'LikMulticlassSoftmax' # LikMulticlassDirichlet, LikMulticlassSoftmax, LikMultipleNormalKron\n",
    "init_val_m = gamma_to_lognormal(np.array([1.]))[0] \\\n",
    "    if lik_type == 'LikMulticlassDirichlet' else np.array([.5])\n",
    "mean_fn_cls = partial(MeanConstant,\n",
    "                      output_dim=output_dim,\n",
    "                      init_val_m=init_val_m,\n",
    "                      flat=False)\n",
    "if lik_type == 'LikMulticlassDirichlet':\n",
    "    lik_cls = partial(LikMulticlassDirichlet,\n",
    "                      output_dim=output_dim,\n",
    "                      init_val_α_ϵ=α_ϵ,\n",
    "                      init_val_α_δ=α_δ,\n",
    "                      n_mc_samples=n_mc_samples)\n",
    "elif lik_type == 'LikMulticlassSoftmax':\n",
    "    lik_cls = partial(LikMulticlassSoftmax,\n",
    "                      output_dim=output_dim,\n",
    "                      n_mc_samples=n_mc_samples)\n",
    "else:\n",
    "    lik_cls = partial(LikMultipleNormalKron,\n",
    "                      output_dim=output_dim)\n",
    "    \n",
    "# previous\n",
    "g_cls = LayerIdentity # CNNTrunk\n",
    "# kx_cls = partial(CovSE, output_scaling=True)\n",
    "kx_cls = partial(CovConvolutional, image_size=(H,W,1), patch_size=patch_size, kg_cls=CovSE)\n",
    "k_cls = partial(CovMultipleOutputIndependent,\n",
    "                k_cls=kx_cls,\n",
    "                output_dim=output_dim,\n",
    "                g_cls=g_cls)\n",
    "\n",
    "Xu_initial = X[np.linspace(0,len(X)-1,n_inducing).astype(np.int32)].copy()\n",
    "Xp_initial = extract_patches_2d_vmap(X.reshape(-1, H, W), patch_size).reshape(-1, 9)\n",
    "Xp_initial = np.array(onp.unique(Xp_initial, axis=0))\n",
    "inducing_loc_cls = partial(InducingLocations,\n",
    "                           shape=(n_inducing, 196),\n",
    "                           init_fn_inducing=lambda k,s: Xu_initial)\n",
    "\n",
    "model = SVGP(mean_fn_cls=mean_fn_cls,\n",
    "             k_cls=k_cls,\n",
    "             lik_cls=lik_cls,\n",
    "             inducing_loc_cls=inducing_loc_cls,\n",
    "             n_data=len(X),\n",
    "             output_dim=output_dim)\n",
    "\n",
    "\n",
    "params = model.get_init_params(model, key)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae11288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_AdamHyperParams(learning_rate=0.0, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.0)\n",
      "['/params/Xu/X', '/params/mean_fn/c']\n",
      "_AdamHyperParams(learning_rate=0.01, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.0)\n",
      "['/params/k/ks_0/kg/ls', '/params/k/ks_0/kg/σ2', '/params/k/ks_1/kg/ls', '/params/k/ks_1/kg/σ2']\n",
      "_AdamHyperParams(learning_rate=0.03, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.0)\n",
      "['/params/q/L', '/params/q/μ']\n"
     ]
    }
   ],
   "source": [
    "# load pretrained weights & set initial values\n",
    "if g_cls != LayerIdentity:\n",
    "    encoder_params = pytree_load({'params': params['params']['k']['g']}, cnn_save_path)\n",
    "    encoder_params_kvs = pytree_get_kvs(encoder_params)\n",
    "    params = pytree_mutate(params, {f'params/k/g/{k}': v for k,v in encoder_params_kvs.items()})\n",
    "params = pytree_mutate(params, {f'params/k/ks_{i}/ls': softplus_inv(np.array([2.]))\n",
    "                                for i in range(output_dim)})\n",
    "\n",
    "kwd_notrain = ['mean_fn', 'Xu/X']\n",
    "kwd_trainslow = [] # Xu/T\n",
    "params_wrap = flax_params2model(model, params)\n",
    "opt = flax_create_multioptimizer(\n",
    "    params_wrap, 'Adam',\n",
    "    [{'learning_rate': 0.}, {'learning_rate': .01}, {'learning_rate': .03}],\n",
    "    [lambda p, v: pytree_path_contains_keywords(p, kwd_notrain),\n",
    "     lambda p, v: pytree_path_contains_keywords(p, kwd_trainslow),\n",
    "     lambda p, v: not pytree_path_contains_keywords(p, kwd_notrain+kwd_trainslow)])\n",
    "\n",
    "flax_check_multiopt(params_wrap, opt)\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becee9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0| 0.00%]\tTime=116.617\tLoss=33568.738\tk.ls=[1. 1.]\tk.σ2=[1. 1.]\tacc=0.700\t\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "import time\n",
    "        \n",
    "@jax.jit\n",
    "def eval_model(params):\n",
    "    Xt, Yt = test_data\n",
    "    Ey, Vy = model.apply(params, Xt, method=model.pred_y, rngs={'lik_mc_samples': key})\n",
    "    pred = np.argmax(Ey, -1).reshape(-1, 1)\n",
    "    acc = np.mean(pred == Yt)\n",
    "    return acc\n",
    "\n",
    "@jax.jit\n",
    "def train_step2(step, opt, batch, key):\n",
    "    key, subkey = random.split(key)\n",
    "    Xb, yb = batch\n",
    "    y_onehot = jax.nn.one_hot(yb.squeeze(), num_classes=output_dim).reshape((-1,output_dim))\n",
    "    def loss_fn(params):\n",
    "        fx = model.apply(params,\n",
    "                         (Xb, y_onehot),\n",
    "                         method=model.mll,\n",
    "                         rngs={'lik_mc_samples': subkey})\n",
    "        return -fx, {}\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    params = flax_model2params(opt.target)\n",
    "    (loss, aux), grad = grad_fn(params)\n",
    "    opt = opt.apply_gradient(flax_params2model(model, grad))\n",
    "    insert_str = '/kg' if isinstance(model.k_cls().k_cls(), CovConvolutional) else ''\n",
    "    log = {'loss': loss,\n",
    "           'k.ls': jax.nn.softplus(pytree_leaf(params, f'params/k/kx/ls')\n",
    "                                   if isinstance(model.k_cls(), CovICM) else \n",
    "                                   np.hstack([pytree_leaf(params, f'params/k/ks_{i}{insert_str}/ls')\n",
    "                                              for i in range(output_dim)])),\n",
    "           'k.σ2': jax.nn.softplus(pytree_leaf(params, f'params/k/kx/σ2')\n",
    "                                   if isinstance(model.k_cls(), CovICM) else \n",
    "                                   np.hstack([pytree_leaf(params, f'params/k/ks_{i}{insert_str}/σ2')\n",
    "                                              for i in range(output_dim)]))}\n",
    "    return opt, log, key\n",
    "\n",
    "\n",
    "bsz = 3\n",
    "train_n_batches, train_batches = get_data_stream(key, bsz, data)\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    for it in range(train_n_batches):\n",
    "        step = epoch*train_n_batches+it\n",
    "        batch = next(train_batches)\n",
    "        opt, log, key = train_step2(step, opt, batch, key)\n",
    "        params = flax_model2params(opt.target)\n",
    "        if step%(train_n_batches*n_epochs//30)==0:\n",
    "            acc = eval_model(params)\n",
    "            print(f'[{epoch:3}|{100*it/train_n_batches:5.2f}%]\\t'\n",
    "                  f'Time={time.time()-start:.3f}\\t'\n",
    "                  f'Loss={log[\"loss\"]:.3f}\\t'\n",
    "                  f'k.ls={log[\"k.ls\"][:3]}\\t'\n",
    "                  f'k.σ2={log[\"k.σ2\"][:3]}\\t'\n",
    "                  f'acc={acc:.3f}\\t')\n",
    "            start = time.time()\n",
    "\n",
    "\n",
    "params = flax_model2params(opt.target)\n",
    "\n",
    "\n",
    "# acc\n",
    "# pretrained cnntrunk: .96 (bsz=5, n_inducing=50%)\n",
    "# just rbf kernel: .63\n",
    "# convolutional with rbf base kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d4b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Sequence, Optional, Tuple, Union, List, Iterable\n",
    "\n",
    "\n",
    "class CovConvolutional(Kernel):\n",
    "    \"\"\" Convolutional Kernel f~GP(0,k)\n",
    "            where k(x,x') = ΣpΣp' kᵧ(X[p], X[p'])\n",
    "                  kᵧ(z,z') is the patch kernel\n",
    "    \"\"\"\n",
    "    image_size: Tuple[int] = (28, 28, 1) # (H, W, C)\n",
    "    patch_size: Tuple[int] = (3, 3)      # (h, w)\n",
    "    kg_cls: Callable = CovSE\n",
    "\n",
    "    def setup(self):\n",
    "        self.kg = self.kg_cls()\n",
    "    \n",
    "    def kp(self, Xp, Yp, full_cov):\n",
    "        \"\"\" Computes yet-to-be summed kernel `self.kg`\n",
    "\n",
    "            Xp    (N, P, h, w)\n",
    "            Yp    (M, P, h, w)\n",
    "            Returns\n",
    "                (N, P, M, P) if `Yp` not None \n",
    "                    Computes K(X,Y)\n",
    "                (N, P, P) if `Yp` is None\n",
    "                    Computes K(X)\n",
    "        \"\"\"\n",
    "        if full_cov:\n",
    "            Xp_shape = Xp.shape # (N, P, h, w)\n",
    "            Xp = Xp.reshape(-1, self.patch_len) # (N*P, h*w)\n",
    "            Yp_shape = Yp.shape if Yp is not None else Xp_shape # (M, P, h, w)\n",
    "            Yp = Yp.reshape(-1, self.patch_len) if Yp is not None else Yp # (M*P, h*w)\n",
    "            Kp = self.kg(Xp, Yp, full_cov=full_cov) # (N*P, M*P)\n",
    "            Kp = Kp.reshape(Xp_shape[:2]+Yp_shape[:2]) # (N, P, M, P)\n",
    "        else:\n",
    "            Xp_shape = Xp.shape\n",
    "            Xp = Xp.reshape((Xp_shape[0], Xp_shape[1], -1)) # (N, P, h*w)\n",
    "            Kp = vmap(self.kg, (0, None, None), 0)(Xp, None, True) # (N, P, P)\n",
    "        return Kp\n",
    "        \n",
    "    def get_patches(self, X):\n",
    "        \"\"\" (N, H, W, 1) -> # (N, P, h, w) where P=#patches \"\"\"\n",
    "        patches = extract_patches_2d_vmap(X.reshape((-1, *self.image_size)),\n",
    "                                          self.patch_size)\n",
    "        if patches.shape[1] != self.num_patches:\n",
    "            raise ValueError('#patches extracted not correct')\n",
    "        return patches\n",
    "\n",
    "    def K(self, X, Y=None):\n",
    "        Xp = self.get_patches(X)\n",
    "        Yp = None if Y is None else self.get_patches(Y)\n",
    "        Kp = self.kp(Xp, Yp, full_cov=True)\n",
    "        K = np.mean(Kp, axis=[1, 3])\n",
    "        return K\n",
    "\n",
    "    def Kdiag(self, X, Y=None):\n",
    "        Xp = self.get_patches(X)\n",
    "        Kp = self.kp(Xp, None, full_cov=False)\n",
    "        K = np.mean(Kp, axis=[1, 2])\n",
    "        return K\n",
    "\n",
    "    @property\n",
    "    def patch_len(self):\n",
    "        return self.patch_size[0]*self.patch_size[1]\n",
    "    \n",
    "    @property\n",
    "    def num_patches(self):\n",
    "        H, W, C = self.image_size\n",
    "        h, w = self.patch_size\n",
    "        return (H-h+1)*(W-w+1)*C\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# x = random.normal(key, (4,14,14,1))\n",
    "# y = random.normal(key, (5,14,14,1))\n",
    "# k = CovConvolutional(image_size=(14,14,1), patch_size=(3,3))\n",
    "# params = k.init(key, x)\n",
    "# K = k.apply(params, x, full_cov=False)\n",
    "# K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f534dfd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "             [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "             [0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "             [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "             [0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "             [0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "             [0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "             [0., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
       "             [0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "             [0., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "             [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "             [0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
       "             [0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "             [0., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
       "             [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "             [0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "             [0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
       "             [0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "             [0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "             [0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
       "             [0., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
       "             [0., 1., 0., 0., 1., 0., 1., 1., 0.],\n",
       "             [0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
       "             [0., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
       "             [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "             [0., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
       "             [0., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
       "             [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "             [1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "             [1., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "             [1., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
       "             [1., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "             [1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "             [1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
       "             [1., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "             [1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "             [1., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
       "             [1., 1., 0., 0., 1., 0., 1., 1., 0.],\n",
       "             [1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "             [1., 1., 1., 0., 0., 0., 1., 1., 1.],\n",
       "             [1., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "             [1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
       "             [1., 1., 1., 1., 0., 0., 1., 0., 0.],\n",
       "             [1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
       "             [1., 1., 1., 1., 0., 1., 1., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b2e89f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cxr] *",
   "language": "python",
   "name": "conda-env-cxr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
