{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torchvision \n",
    "import torchvision.transforms as tv_transforms\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.utils as tv_utils\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from fid import calculate_activation_statistics\n",
    "from models_classifier import MnistCNN\n",
    "from models_cgan import apply_sn, Discriminator, ConditionalDiscriminator, ConditionalGenerator, ConditionalResidualBlock, ConditionalBatchNorm2d, conv3x3\n",
    "from inception import InceptionV3\n",
    "from datasets import ColorMNIST\n",
    "from plot_tools import plot_im\n",
    "from utils import makedirs_exists_ok, seed_rng, set_cuda_visible_devices, load_weights_from_file, bin_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cgan_jpt'\n",
    "data_root = './data'\n",
    "model_root = f'./models/{model_name}'\n",
    "figure_root = f'./figures/{model_name}'\n",
    "log_root = f'./logs/{model_name}'\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "seed = 1\n",
    "gpu_id = '0'\n",
    "n_workers = 8\n",
    "load_weights = ''\n",
    "lr = 0.0002\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "n_epochs = 20\n",
    "log_interval = 100\n",
    "tsboard = True\n",
    "\n",
    "target_type = 'color'\n",
    "dim_z = 50\n",
    "num_classes = 10\n",
    "im_channels = 3\n",
    "conditional = True\n",
    "load_weights_mnist_cnn = './models/mnist_cnn_color/mnist_cnn_49.pt'\n",
    "\n",
    "delta = 1/num_classes\n",
    "\n",
    "lambda_gan = 1\n",
    "lambda_cyc = 200\n",
    "lambda_cls = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalConditionalDiscriminator(Discriminator):\n",
    "    \"\"\" conditional discriminator where the conditioned variable is ordinal\n",
    "    \n",
    "        Taken from:\n",
    "            https://github.com/batmanlab/Explanation_by_Progressive_Exaggeration/blob/master/src/explainer.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conv_channels, conv_dnsample, num_classes, use_sn=True):\n",
    "        \"\"\"\n",
    "            Projection cGAN (ImageNet)\n",
    "                conv_channels = [3, 64, 128, 256, 512, 1024, 1024]\n",
    "                conv_dnsample = [True, True, True, True, True, False]\n",
    "        \"\"\"\n",
    "        super(OrdinalConditionalDiscriminator, self).__init__(conv_channels, conv_dnsample, use_sn=use_sn)\n",
    "        \n",
    "        self.c_embed = apply_sn(nn.Embedding(num_classes, conv_channels[-1]), use_sn)\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        \"\"\" x    batch_size x im_channels x h x w\n",
    "            c    batch_size\n",
    "        \"\"\"\n",
    "        c = c.view(-1)\n",
    "        # conv_channels = [3, 64, 128, 256, 512, 1024, 1024]\n",
    "        # conv_dnsample = [True, True, True, True, True]\n",
    "        #\n",
    "        # 3x128x128\n",
    "        x = self.residual_blocks(x)\n",
    "        # 1024x4x4\n",
    "        x = self.nonlinearity(x)\n",
    "        x = torch.sum(x, dim=(2,3))   # (global sum pooling)\n",
    "        # 1024\n",
    "        \n",
    "        # sigmoid^-1(p(real/fake|x,c)) =\n",
    "        #     log(p_data(x)/p_model(x)) + \n",
    "        #     log(p_data(c|x)/p_model(c|x))\n",
    "        all_classes = torch.arange(0, num_classes, dtype=torch.long, device=x.device)\n",
    "        W = x @ self.c_embed(all_classes).T\n",
    "        W = torch.cumsum(W, dim=1)\n",
    "        # 10\n",
    "        f_1 = W.gather(dim=1, index=c.view(-1,1))\n",
    "        f_2 = self.linear(x)\n",
    "        \n",
    "        x = f_1 + f_2\n",
    "        # 1\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ConditionalAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_channels, dec_channels, num_classes,\n",
    "                 dim_z = 128,\n",
    "                 im_channels = 3):\n",
    "        \"\"\"\n",
    "            enc_channels\n",
    "                [64, 128, 256, 256]\n",
    "                   c1   c2   c3\n",
    "            dec_channels\n",
    "                [256, 128, 64, 64]\n",
    "                   c1   c2   c3\n",
    "            num_classes\n",
    "                if not None, use conditional batchnorm\n",
    "        \"\"\"\n",
    "        super(ConditionalAutoencoder, self).__init__()\n",
    "        \n",
    "        n_enc_blks = len(enc_channels) - 1\n",
    "        n_dec_blks = len(dec_channels) - 1\n",
    "        assert(n_enc_blks > 0)\n",
    "        assert(n_dec_blks > 0)\n",
    "        \n",
    "        self.n_enc_blks = n_enc_blks\n",
    "        self.n_dec_blks = n_dec_blks\n",
    "        self.bottom_width = 4\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "        \n",
    "        resblk_cls = ConditionalResidualBlock\n",
    "        norm_layer = lambda num_features: ConditionalBatchNorm2d(num_features, num_classes)\n",
    "        \n",
    "        self.normalization_initial = norm_layer(im_channels)\n",
    "        self.conv_initial = conv3x3(im_channels, enc_channels[0])\n",
    "        \n",
    "        for i in range(n_enc_blks):\n",
    "            self.add_module(\n",
    "                f'residual_block_enc_{i}',\n",
    "                resblk_cls(enc_channels[i], enc_channels[i+1],\n",
    "                           resample = \"dn\",\n",
    "                           norm_layer = norm_layer,\n",
    "                           nonlinearity = self.nonlinearity,\n",
    "                           resblk_1st = True if i == 0 else False))\n",
    "        \n",
    "        for i in range(n_dec_blks):\n",
    "            self.add_module(\n",
    "                f'residual_block_dec_{i}',\n",
    "                resblk_cls(dec_channels[i], dec_channels[i+1],\n",
    "                           resample = \"up\",\n",
    "                           norm_layer = norm_layer,\n",
    "                           nonlinearity = self.nonlinearity))\n",
    "            \n",
    "        self.normalization_final = norm_layer(dec_channels[-1])\n",
    "        self.conv_final = conv3x3(dec_channels[-1], im_channels)\n",
    "        self.nonlinearity_final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\" x    batch_size x im_channels x h x w\n",
    "            c    batch_size\n",
    "            Returns  \n",
    "                 batch_size x im_channels x h x w\n",
    "        \"\"\"\n",
    "        c = c.view(-1)\n",
    "        # bottom_width = 4\n",
    "        # enc_channels = [64, 128, 256, 256]\n",
    "        # dec_channels = [256, 128, 64, 64]\n",
    "        # im_channnels = 3\n",
    "        #\n",
    "        # 3x32x32\n",
    "        x = self.normalization_initial(x, c)\n",
    "        x = self.nonlinearity(x)\n",
    "        x = self.conv_initial(x)\n",
    "        # 64x32x32\n",
    "        for i in range(self.n_enc_blks):\n",
    "            x = getattr(self, f'residual_block_enc_{i}')(x, c)\n",
    "        # 256x4x4\n",
    "        z = x\n",
    "        # 256x4x4\n",
    "        for i in range(self.n_dec_blks):\n",
    "            x = getattr(self, f'residual_block_dec_{i}')(x, c)\n",
    "        # 64x32x32\n",
    "        x = self.normalization_final(x, c)\n",
    "        x = self.nonlinearity(x)\n",
    "        x = self.conv_final(x)\n",
    "        x = self.nonlinearity_final(x)\n",
    "        # 3x32x32\n",
    "        return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## conditional D\n",
    "##############################\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "conv_channels = [3, 64, 128, 256]\n",
    "conv_dnsample = [True, True, True]\n",
    "D = OrdinalConditionalDiscriminator(conv_channels, conv_dnsample, num_classes)\n",
    "\n",
    "\n",
    "x = torch.rand((50, 3, 32, 32))\n",
    "c = torch.empty((50, 1), dtype=torch.long).random_(0, num_classes)\n",
    "out = D(x, c)\n",
    "\n",
    "print(x.shape, out.shape)\n",
    "\n",
    "##############################\n",
    "## conditional autoencoder\n",
    "##############################\n",
    "\n",
    "num_classes = 10\n",
    "enc_channels = [64, 128, 256, 256]\n",
    "dec_channels = [256, 128, 64, 64]\n",
    "im_channnels = 3\n",
    "\n",
    "G = ConditionalAutoencoder(enc_channels, dec_channels, num_classes, im_channels=im_channels)\n",
    "\n",
    "x = torch.rand((50, 3, 32, 32))\n",
    "c = torch.empty((50, 1), dtype=torch.long).random_(0, num_classes)\n",
    "xhat, z = G(x, c)\n",
    "\n",
    "print(x.shape, xhat.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(figure_root, exist_ok=True)\n",
    "os.makedirs(model_root,  exist_ok=True)\n",
    "os.makedirs(log_root,    exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(log_root)\n",
    "writer.flush()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transforms = tv_transforms.Compose([\n",
    "    tv_transforms.Resize(image_size),\n",
    "    tv_transforms.ToTensor(),\n",
    "    tv_transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ColorMNIST(root=data_root, download=True, train=True, transform=transforms),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=True)\n",
    "\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(\n",
    "    ColorMNIST(root=data_root, download=True, train=False, transform=transforms),\n",
    "    batch_size=10, shuffle=True, num_workers=n_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classifier of mnist color \n",
    "#\n",
    "K = MnistCNN(3, 1, 32).to(device).eval()\n",
    "load_weights_from_file(K, load_weights_mnist_cnn)\n",
    "\n",
    "def K_posterior_prob(x):\n",
    "    return F.sigmoid(K(x)).view(-1)\n",
    "\n",
    "def K_signal(x, delta = 0):\n",
    "    return bin_index(torch.clamp(K_posterior_prob(x) + delta, 0, 1), n_bins=num_classes)\n",
    "\n",
    "x = next(iter(test_loader))[0].to(device)\n",
    "print(K_signal(x, delta))\n",
    "plot_im(x, nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_channels = [256, 256, 128, 64]\n",
    "conv_upsample = [True, True, True]\n",
    "\n",
    "enc_channels = [64, 128, 256, 256]\n",
    "dec_channels = [256, 128, 64, 64]\n",
    "\n",
    "conv_channels = [im_channels, 64, 128, 256]\n",
    "conv_dnsample = [True, True, True]\n",
    "\n",
    "G = ConditionalAutoencoder(enc_channels, dec_channels, num_classes=num_classes, dim_z=dim_z, im_channels=im_channels).to(device)\n",
    "# G = ConditionalGenerator(conv_channels, conv_upsample, num_classes=num_classes, dim_z=dim_z, im_channels=im_channels).to(device)\n",
    "D = OrdinalConditionalDiscriminator(conv_channels, conv_dnsample, num_classes, use_sn=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_D = nn.BCEWithLogitsLoss()\n",
    "critereon_cyc = torch.nn.L1Loss()\n",
    "criterion_rec = torch.nn.MSELoss()\n",
    "criterion_cls = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr, (beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr, (beta1, beta2))\n",
    "\n",
    "fixed_x = next(iter(test_loader))[0].repeat_interleave(10, dim=0).to(device)\n",
    "fixed_z = torch.randn(100, dim_z).to(device)\n",
    "fixed_c = torch.arange(10).repeat(10).to(device)\n",
    "\n",
    "real_label, fake_label = 0, 1\n",
    "\n",
    "plot_im(fixed_x, nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for it, (x_real, c_digit, c_color) in enumerate(train_loader):\n",
    "\n",
    "        # batch_size for last batch might be different ...\n",
    "        batch_size = x_real.size(0)\n",
    "        real_labels = torch.full((batch_size, 1), real_label, device=device)\n",
    "        fake_labels = torch.full((batch_size, 1), fake_label, device=device)\n",
    "        \n",
    "        \n",
    "        if target_type == 'digit':\n",
    "            c_real = c_digit\n",
    "        elif target_type == 'color':\n",
    "            c_real = bin_index(c_color, num_classes)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        \n",
    "        # use logit or classification ?\n",
    "        x_real = x_real.to(device)\n",
    "        c_real = K_signal(x_real, 0)\n",
    "        \n",
    "        ##############################################################\n",
    "        # Update Discriminator\n",
    "        ##############################################################\n",
    "        \n",
    "        y = D(x_real, c_real)\n",
    "        loss_D_adv_real = criterion_D(y, real_labels)\n",
    "        \n",
    "        # a minibatch of samples from model distribution\n",
    "        # x_real -- encode - z - decode --> x_fake -- D --> y \n",
    "        # c_fake                            c_fake\n",
    "        #\n",
    "        c_fake = torch.empty(batch_size, dtype=torch.long).random_(0, num_classes).to(device)\n",
    "\n",
    "        x_fake, _ = G(x_real, c_fake)\n",
    "        y = D(x_fake, c_fake)\n",
    "        loss_D_adv_fake = criterion_D(y, fake_labels)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D_adv = lambda_gan * (loss_D_adv_real + loss_D_adv_fake)\n",
    "        loss_D = loss_D_adv\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        ##############################################################\n",
    "        # Update Generator/Encoder\n",
    "        ##############################################################\n",
    "        \n",
    "        \n",
    "        # a minibatch of samples from model distribution\n",
    "        # x_real -- encode - z - decode --> x_fake -- D --> y \n",
    "        # c_fake                            c_fake\n",
    "        #\n",
    "        c_fake = torch.empty(batch_size, dtype=torch.long).random_(0, num_classes).to(device)\n",
    "        x_fake, _ = G(x_real, c_fake)\n",
    "        y = D(x_fake, c_fake)\n",
    "        loss_G_adv = criterion_D(y, real_labels)\n",
    "        \n",
    "        x_fake_cyc, z_fake_cyc = G(x_fake, c_real)\n",
    "        x_fake_rec, z_fake_rec = G(x_real, c_real)\n",
    "        loss_G_cyc = critereon_cyc(x_fake_cyc, x_real)\n",
    "        loss_G_rec = criterion_rec(z_fake_cyc, z_fake_rec)\n",
    "        \n",
    "        fake_evaluation = criterion_cls(K(x_real).view(-1), c_fake.type(torch.float32) * delta)\n",
    "        recons_evaluation = criterion_cls(K(x_fake_cyc), F.sigmoid(K(x_real)))\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G_adv = lambda_gan * loss_G_adv\n",
    "        loss_G_cyc = lambda_cyc * (loss_G_cyc + loss_G_rec)\n",
    "        loss_G_cls = lambda_cls * (fake_evaluation + recons_evaluation)\n",
    "        loss_G = loss_G_adv + loss_G_cyc + loss_G_cls\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ##############################################################\n",
    "        # print\n",
    "        ##############################################################\n",
    "\n",
    "        loss_D_adv = loss_D_adv.item()\n",
    "        loss_G_adv = loss_G_adv.item()\n",
    "        loss_G_cyc = loss_G_cyc.item()\n",
    "        loss_G_cls = loss_G_cls.item()\n",
    "        loss_total = loss_D + loss_G\n",
    "\n",
    "        global_step = epoch*len(train_loader)+it\n",
    "        \n",
    "        if tsboard:\n",
    "            writer.add_scalar('loss/total', loss_total, global_step)\n",
    "            writer.add_scalar('loss/D_adv', loss_D_adv, global_step)\n",
    "            writer.add_scalar('loss/G_adv', loss_G_adv, global_step)\n",
    "            writer.add_scalar('loss/G_cyc', loss_G_cyc, global_step)\n",
    "            writer.add_scalar('loss/G_cls', loss_G_cls, global_step)\n",
    "\n",
    "        if it % log_interval == log_interval-1:\n",
    "            print(f'[{epoch+1}/{n_epochs}]\\t'\n",
    "                  f'[{(it+1)*batch_size}/{len(train_loader.dataset)} ({100.*(it+1)/len(train_loader):.0f}%)]\\t'\n",
    "                  f'loss: {loss_total:.4}\\t'\n",
    "                  f'loss_D_adv: {loss_D_adv:.4}\\t'\n",
    "                  f'loss_G_adv: {loss_G_adv:.4}\\t'\n",
    "                  f'loss_G_cyc: {loss_G_cyc:.4}\\t'\n",
    "                  f'loss_G_cls: {loss_G_cls:.4}\\t')\n",
    "            \n",
    "            x_fake, _ = G(fixed_x, fixed_c)\n",
    "            tv_utils.save_image(x_fake,\n",
    "                os.path.join(figure_root,\n",
    "                    f'{model_name}_fake_samples_epoch={epoch}_it={it}.png'), nrow=10, normalize=True)\n",
    "            \n",
    "            if tsboard:\n",
    "                writer.add_image('mnist', tv_utils.make_grid(x_fake, nrow=10, normalize=True), global_step)\n",
    "        \n",
    "\n",
    "#     torch.save(G.state_dict(), os.path.join(model_root, f'G_epoch_{epoch}.pt'))\n",
    "#     torch.save(D.state_dict(), os.path.join(model_root, f'D_epoch_{epoch}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
