
@article{johnsonComposingGraphicalModels2016,
	title = {Composing graphical models with neural networks for structured representations and fast inference},
	url = {http://arxiv.org/abs/1603.06277},
	abstract = {We propose a general modeling and inference framework that composes probabilistic graphical models with deep learning methods and combines their respective strengths. Our model family augments graphical structure in latent variables with neural network observation models. For inference, we extend variational autoencoders to use graphical model approximating distributions with recognition networks that output conjugate potentials. All components of these models are learned simultaneously with a single objective, giving a scalable algorithm that leverages stochastic variational inference, natural gradients, graphical model message passing, and the reparameterization trick. We illustrate this framework with several example models and an application to mouse behavioral phenotyping.},
	journaltitle = {{arXiv}:1603.06277 [stat]},
	author = {Johnson, Matthew J. and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
	urldate = {2019-10-03},
	date = {2016-03-20},
	eprinttype = {arxiv},
	eprint = {1603.06277},
	file = {Johnson et al_2016_Composing graphical models with neural networks for structured representations and fast inference.pdf:/Users/markwang/DropBox (MIT)/zotero/Johnson et al_2016_Composing graphical models with neural networks for structured representations and fast inference.pdf:application/pdf}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
	title = {An Introduction to Variational Autoencoders},
	volume = {abs/1906.02691},
	abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
	journaltitle = {{ArXiv}},
	author = {Kingma, Diederik P. and Welling, M.},
	date = {2019},
	eprinttype = {arxiv},
	eprint = {1906.02691},
	file = {Kingma_Welling_2019_An Introduction to Variational Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Kingma_Welling_2019_An Introduction to Variational Autoencoders.pdf:application/pdf}
}

@article{doerschTutorialVariationalAutoencoders2016,
	title = {Tutorial on Variational Autoencoders},
	url = {http://arxiv.org/abs/1606.05908},
	abstract = {In just three years, Variational Autoencoders ({VAEs}) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. {VAEs} are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. {VAEs} have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, {CIFAR} images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind {VAEs}, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
	journaltitle = {{arXiv}:1606.05908 [cs, stat]},
	author = {Doersch, Carl},
	urldate = {2019-11-12},
	date = {2016-08-13},
	eprinttype = {arxiv},
	eprint = {1606.05908},
	file = {Doersch_2016_Tutorial on Variational Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Doersch_2016_Tutorial on Variational Autoencoders.pdf:application/pdf}
}

@article{kingmaAutoEncodingVariationalBayes2014,
	title = {Auto-Encoding Variational Bayes},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	journaltitle = {{arXiv}:1312.6114 [cs, stat]},
	author = {Kingma, Diederik P. and Welling, Max},
	urldate = {2019-11-13},
	date = {2014-05-01},
	eprinttype = {arxiv},
	eprint = {1312.6114},
	file = {Kingma_Welling_2014_Auto-Encoding Variational Bayes.pdf:/Users/markwang/DropBox (MIT)/zotero/Kingma_Welling_2014_Auto-Encoding Variational Bayes.pdf:application/pdf}
}

@inproceedings{vincentExtractingComposingRobust2008,
	location = {New York, {NY}, {USA}},
	title = {Extracting and Composing Robust Features with Denoising Autoencoders},
	isbn = {978-1-60558-205-4},
	url = {http://doi.acm.org/10.1145/1390156.1390294},
	doi = {10.1145/1390156.1390294},
	series = {{ICML} '08},
	abstract = {Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.},
	pages = {1096--1103},
	booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	publisher = {{ACM}},
	author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
	urldate = {2019-11-13},
	date = {2008},
	note = {event-place: Helsinki, Finland},
	file = {Vincent et al_2008_Extracting and Composing Robust Features with Denoising Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Vincent et al_2008_Extracting and Composing Robust Features with Denoising Autoencoders.pdf:application/pdf}
}

@article{kingmaSemiSupervisedLearningDeep2014,
	title = {Semi-Supervised Learning with Deep Generative Models},
	url = {http://arxiv.org/abs/1406.5298},
	abstract = {The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.},
	journaltitle = {{arXiv}:1406.5298 [cs, stat]},
	author = {Kingma, Diederik P. and Rezende, Danilo J. and Mohamed, Shakir and Welling, Max},
	urldate = {2019-11-16},
	date = {2014-10-31},
	eprinttype = {arxiv},
	eprint = {1406.5298},
	file = {Kingma et al_2014_Semi-Supervised Learning with Deep Generative Models.pdf:/Users/markwang/DropBox (MIT)/zotero/Kingma et al_2014_Semi-Supervised Learning with Deep Generative Models.pdf:application/pdf}
}

@article{kimSemiAmortizedVariationalAutoencoders2018,
	title = {Semi-Amortized Variational Autoencoders},
	url = {http://arxiv.org/abs/1802.02550},
	abstract = {Amortized variational inference ({AVI}) replaces instance-specific local inference with a global inference network. While {AVI} has enabled efficient training of deep generative models such as variational autoencoders ({VAE}), recent empirical work suggests that inference networks can produce suboptimal variational parameters. We propose a hybrid approach, to use {AVI} to initialize the variational parameters and run stochastic variational inference ({SVI}) to refine them. Crucially, the local {SVI} procedure is itself differentiable, so the inference network and generative model can be trained end-to-end with gradient-based optimization. This semi-amortized approach enables the use of rich generative models without experiencing the posterior-collapse phenomenon common in training {VAEs} for problems like text generation. Experiments show this approach outperforms strong autoregressive and variational baselines on standard text and image datasets.},
	journaltitle = {{arXiv}:1802.02550 [cs, stat]},
	author = {Kim, Yoon and Wiseman, Sam and Miller, Andrew C. and Sontag, David and Rush, Alexander M.},
	urldate = {2019-11-19},
	date = {2018-07-23},
	eprinttype = {arxiv},
	eprint = {1802.02550},
	file = {Kim et al_2018_Semi-Amortized Variational Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Kim et al_2018_Semi-Amortized Variational Autoencoders.pdf:application/pdf}
}

@incollection{kingmaImprovedVariationalInference2016a,
	title = {Improved Variational Inference with Inverse Autoregressive Flow},
	url = {http://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow.pdf},
	pages = {4743--4751},
	booktitle = {Advances in Neural Information Processing Systems 29},
	publisher = {Curran Associates, Inc.},
	author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	urldate = {2019-12-01},
	date = {2016},
	file = {Kingma et al_2016_Improved Variational Inference with Inverse Autoregressive Flow.pdf:/Users/markwang/DropBox (MIT)/zotero/Kingma et al_2016_Improved Variational Inference with Inverse Autoregressive Flow.pdf:application/pdf}
}

@article{chenIsolatingSourcesDisentanglement2019,
	title = {Isolating Sources of Disentanglement in Variational Autoencoders},
	url = {http://arxiv.org/abs/1802.04942},
	abstract = {We decompose the evidence lower bound to show the existence of a term measuring the total correlation between latent variables. We use this to motivate our \${\textbackslash}beta\$-{TCVAE} (Total Correlation Variational Autoencoder), a refinement of the state-of-the-art \${\textbackslash}beta\$-{VAE} objective for learning disentangled representations, requiring no additional hyperparameters during training. We further propose a principled classifier-free measure of disentanglement called the mutual information gap ({MIG}). We perform extensive quantitative and qualitative experiments, in both restricted and non-restricted settings, and show a strong relation between total correlation and disentanglement, when the latent variables model is trained using our framework.},
	journaltitle = {{arXiv}:1802.04942 [cs, stat]},
	author = {Chen, Ricky T. Q. and Li, Xuechen and Grosse, Roger and Duvenaud, David},
	urldate = {2019-12-03},
	date = {2019-04-23},
	eprinttype = {arxiv},
	eprint = {1802.04942},
	file = {Chen et al_2019_Isolating Sources of Disentanglement in Variational Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Chen et al_2019_Isolating Sources of Disentanglement in Variational Autoencoders.pdf:application/pdf}
}

@article{locatelloChallengingCommonAssumptions2019,
	title = {Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations},
	url = {http://arxiv.org/abs/1811.12359},
	abstract = {The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.},
	journaltitle = {{arXiv}:1811.12359 [cs, stat]},
	author = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Rätsch, Gunnar and Gelly, Sylvain and Schölkopf, Bernhard and Bachem, Olivier},
	urldate = {2019-12-03},
	date = {2019-06-18},
	eprinttype = {arxiv},
	eprint = {1811.12359},
	file = {Locatello et al_2019_Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations.pdf:/Users/markwang/DropBox (MIT)/zotero/Locatello et al_2019_Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations.pdf:application/pdf}
}

@article{higginsBetaVAELearningBasic2016,
	title = {beta-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
	url = {https://openreview.net/forum?id=Sy2fzU9gl},
	shorttitle = {beta-{VAE}},
	abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial...},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	urldate = {2019-12-04},
	date = {2016-11-04},
	file = {Higgins et al_2016_beta-VAE - Learning Basic Visual Concepts with a Constrained Variational Framework.pdf:/Users/markwang/DropBox (MIT)/zotero/Higgins et al_2016_beta-VAE - Learning Basic Visual Concepts with a Constrained Variational Framework.pdf:application/pdf}
}

@article{tomczakVAEVampPrior2018,
	title = {{VAE} with a {VampPrior}},
	url = {http://arxiv.org/abs/1705.07120},
	abstract = {Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder ({VAE}) framework with a new type of prior which we call "Variational Mixture of Posteriors" prior, or {VampPrior} for short. The {VampPrior} consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague {VAEs}. We provide empirical studies on six datasets, namely, static and binary {MNIST}, {OMNIGLOT}, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical {VampPrior} delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to {SOTA} methods for the approach with convolutional networks.},
	journaltitle = {{arXiv}:1705.07120 [cs, stat]},
	author = {Tomczak, Jakub M. and Welling, Max},
	urldate = {2019-12-05},
	date = {2018-02-26},
	eprinttype = {arxiv},
	eprint = {1705.07120},
	file = {Tomczak_Welling_2018_VAE with a VampPrior.pdf:/Users/markwang/DropBox (MIT)/zotero/Tomczak_Welling_2018_VAE with a VampPrior.pdf:application/pdf}
}

@article{kimDisentanglingFactorising2019,
	title = {Disentangling by Factorising},
	url = {http://arxiv.org/abs/1802.05983},
	abstract = {We define and address the problem of unsupervised learning of disentangled representations on data generated from independent factors of variation. We propose {FactorVAE}, a method that disentangles by encouraging the distribution of representations to be factorial and hence independent across the dimensions. We show that it improves upon \${\textbackslash}beta\$-{VAE} by providing a better trade-off between disentanglement and reconstruction quality. Moreover, we highlight the problems of a commonly used disentanglement metric and introduce a new metric that does not suffer from them.},
	journaltitle = {{arXiv}:1802.05983 [cs, stat]},
	author = {Kim, Hyunjik and Mnih, Andriy},
	urldate = {2019-12-05},
	date = {2019-07-09},
	eprinttype = {arxiv},
	eprint = {1802.05983},
	file = {Kim_Mnih_2019_Disentangling by Factorising.pdf:/Users/markwang/DropBox (MIT)/zotero/Kim_Mnih_2019_Disentangling by Factorising.pdf:application/pdf}
}

@article{zhaoLearningHierarchicalFeatures2017,
	title = {Learning Hierarchical Features from Generative Models},
	url = {http://arxiv.org/abs/1702.08396},
	abstract = {Deep neural networks have been shown to be very successful at learning feature hierarchies in supervised learning tasks. Generative models, on the other hand, have benefited less from hierarchical models with multiple layers of latent variables. In this paper, we prove that hierarchical latent variable models do not take advantage of the hierarchical structure when trained with existing variational methods, and provide some limitations on the kind of features existing models can learn. Finally we propose an alternative architecture that do not suffer from these limitations. Our model is able to learn highly interpretable and disentangled hierarchical features on several natural image datasets with no task specific regularization or prior knowledge.},
	journaltitle = {{arXiv}:1702.08396 [cs, stat]},
	author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
	urldate = {2019-12-10},
	date = {2017-06-09},
	eprinttype = {arxiv},
	eprint = {1702.08396},
	file = {Zhao et al_2017_Learning Hierarchical Features from Generative Models.pdf:/Users/markwang/DropBox (MIT)/zotero/Zhao et al_2017_Learning Hierarchical Features from Generative Models.pdf:application/pdf}
}

@article{rezendeStochasticBackpropagationApproximate2014,
	title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
	url = {http://arxiv.org/abs/1401.4082},
	abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
	journaltitle = {{arXiv}:1401.4082 [cs, stat]},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
	urldate = {2019-12-12},
	date = {2014-05-30},
	eprinttype = {arxiv},
	eprint = {1401.4082},
	file = {Rezende et al_2014_Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:/Users/markwang/DropBox (MIT)/zotero/Rezende et al_2014_Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:application/pdf}
}

@article{chungRecurrentLatentVariable2016,
	title = {A Recurrent Latent Variable Model for Sequential Data},
	url = {http://arxiv.org/abs/1506.02216},
	abstract = {In this paper, we explore the inclusion of latent random variables into the dynamic hidden state of a recurrent neural network ({RNN}) by combining elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational {RNN} ({VRNN})1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the {RNN} dynamic hidden state.},
	journaltitle = {{arXiv}:1506.02216 [cs]},
	author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron and Bengio, Yoshua},
	urldate = {2019-12-12},
	date = {2016-04-06},
	eprinttype = {arxiv},
	eprint = {1506.02216},
	file = {Chung et al_2016_A Recurrent Latent Variable Model for Sequential Data.pdf:/Users/markwang/DropBox (MIT)/zotero/Chung et al_2016_A Recurrent Latent Variable Model for Sequential Data.pdf:application/pdf}
}

@inproceedings{sohnLearningStructuredOutput2015,
	title = {Learning Structured Output Representation using Deep Conditional Generative Models},
	abstract = {Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-{UCSD} Birds 200 and the subset of Labeled Faces in the Wild dataset.},
	booktitle = {{NIPS}},
	author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	date = {2015},
	file = {Sohn et al_2015_Learning Structured Output Representation using Deep Conditional Generative Models.pdf:/Users/markwang/DropBox (MIT)/zotero/Sohn et al_2015_Learning Structured Output Representation using Deep Conditional Generative Models.pdf:application/pdf;Sohn et al_2015_Learning Structured Output Representation using Deep Conditional Generative Models.pdf:/Users/markwang/DropBox (MIT)/zotero/Sohn et al_2015_Learning Structured Output Representation using Deep Conditional Generative Models2.pdf:application/pdf}
}

@article{zhaoInfoVAEInformationMaximizing2018,
	title = {{InfoVAE}: Information Maximizing Variational Autoencoders},
	url = {http://arxiv.org/abs/1706.02262},
	shorttitle = {{InfoVAE}},
	abstract = {A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives ({InfoVAE}) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.},
	journaltitle = {{arXiv}:1706.02262 [cs, stat]},
	author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
	urldate = {2020-01-10},
	date = {2018-05-30},
	eprinttype = {arxiv},
	eprint = {1706.02262},
	file = {Zhao et al_2018_InfoVAE - Information Maximizing Variational Autoencoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Zhao et al_2018_InfoVAE - Information Maximizing Variational Autoencoders.pdf:application/pdf}
}

@article{tolstikhinWassersteinAutoEncoders2019,
	title = {Wasserstein Auto-Encoders},
	url = {http://arxiv.org/abs/1711.01558},
	abstract = {We propose the Wasserstein Auto-Encoder ({WAE})---a new algorithm for building a generative model of the data distribution. {WAE} minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder ({VAE}). This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders ({AAE}). Our experiments show that {WAE} shares many of the properties of {VAEs} (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the {FID} score.},
	journaltitle = {{arXiv}:1711.01558 [cs, stat]},
	author = {Tolstikhin, Ilya and Bousquet, Olivier and Gelly, Sylvain and Schoelkopf, Bernhard},
	urldate = {2020-01-11},
	date = {2019-12-05},
	eprinttype = {arxiv},
	eprint = {1711.01558},
	file = {Tolstikhin et al_2019_Wasserstein Auto-Encoders.pdf:/Users/markwang/DropBox (MIT)/zotero/Tolstikhin et al_2019_Wasserstein Auto-Encoders.pdf:application/pdf}
}