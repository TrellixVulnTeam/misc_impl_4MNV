{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "#\n",
    "import os\n",
    "import itertools\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dcgan import Generator, Discriminator, weights_initialization, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100\n",
    "nfg = 128\n",
    "nfd = 64\n",
    "nc = 1\n",
    "model_name = 'dcgan_seed=1'\n",
    "model_name = f'{model_name}_{datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\")}'\n",
    "data_root = '../data'\n",
    "figure_root = os.path.join('./figures', model_name)\n",
    "model_root = os.path.join('./models', model_name)\n",
    "log_root = os.path.join('./logs', model_name)\n",
    "load_weights_generator = 'models/dcgan_seed=1/G_epoch_29.pt'\n",
    "load_weights_discriminator = 'models/dcgan_seed=1/D_epoch_29.pt'\n",
    "image_size = 64\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "n_epochs = 10\n",
    "n_batches_print = 100\n",
    "seed = 1\n",
    "n_workers = 8\n",
    "gpu_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one(x, color_bar=False):\n",
    "    x = x.detach().cpu().numpy().transpose((1,2,0)).squeeze()\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')\n",
    "    if color_bar:\n",
    "        plt.colorbar(extend='both')\n",
    "    return plt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root=data_root, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(image_size),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,), (0.5,)),\n",
    "                   ]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(trainloader))\n",
    "plot_one(x[0][0])\n",
    "torch.mean(x[0]), torch.std(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = Generator(nz, nfg, nc).to(device)\n",
    "G.apply(weights_initialization)\n",
    "if load_weights_generator != '':\n",
    "    G.load_state_dict(torch.load(load_weights_generator))\n",
    "    \n",
    "D = Discriminator(nc, nfd).to(device)\n",
    "D.apply(weights_initialization)\n",
    "if load_weights_discriminator != '':\n",
    "    D.load_state_dict(torch.load(load_weights_discriminator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Generator Representation\n",
    "\n",
    "##### vary a single dimension of latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dim_varying_z(n_samples, z_range=(-1,1), z_init=torch.zeros((nz, nz, 1, 1), device=device)):\n",
    "    for v in np.linspace(*z_range, n_samples):\n",
    "        z = z_init.clone()\n",
    "        for i in range(nz):\n",
    "            z[i,i,:,:] += v\n",
    "        yield z\n",
    "\n",
    "def all_dim_varying_z(n_samples, z_range=(-1,1)):\n",
    "    z_init=torch.randn((nz, nz, 1, 1), device=device)\n",
    "    for v in np.linspace(*z_range, n_samples):\n",
    "        z = z_init.clone()\n",
    "        for i in range(nz):\n",
    "            z[i,:,:,:] += v\n",
    "        yield z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir1 = './figures/single_dim_varying_z'\n",
    "os.makedirs(out_dir1, exist_ok=True)\n",
    "out_dir2 = './figures/single_dim_varying_z_labeled'\n",
    "os.makedirs(out_dir2, exist_ok=True)\n",
    "    \n",
    "for i, z in enumerate(single_dim_varying_z(100, z_range=(-0.05,0.05))):\n",
    "    x = G(z)\n",
    "    \n",
    "    torchvision.utils.save_image(x, os.path.join(out_dir1,f'{i}.png'), normalize=True, nrow=10)\n",
    "    \n",
    "    x = torchvision.utils.make_grid(x, normalize=True, nrow=10)\n",
    "    x = x.detach().cpu().numpy().transpose((1,2,0)).squeeze()\n",
    "    plt.imshow(x)\n",
    "    plt.text(0, 0, f'{i}', horizontalalignment='left', verticalalignment='bottom', color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(out_dir2,f'{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir1 = './figures/all_dim_varying_z'\n",
    "os.makedirs(out_dir1, exist_ok=True)\n",
    "out_dir2 = './figures/all_dim_varying_z_labeled'\n",
    "os.makedirs(out_dir2, exist_ok=True)\n",
    "    \n",
    "for i, z in enumerate(all_dim_varying_z(100)):\n",
    "    x = G(z)\n",
    "    \n",
    "    torchvision.utils.save_image(x, os.path.join(out_dir1,f'{i}.png'), normalize=True, nrow=10)\n",
    "    \n",
    "    x = torchvision.utils.make_grid(x, normalize=True, nrow=10)\n",
    "    x = x.detach().cpu().numpy().transpose((1,2,0)).squeeze()\n",
    "    plt.imshow(x)\n",
    "    plt.text(0, 0, f'{i}', horizontalalignment='left', verticalalignment='bottom', color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(out_dir2,f'{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### given 2 latents, interpolate between the two, visualize in model distribution space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(z1, z2, alpha):\n",
    "    \"\"\" Interpolate between each latent vector in minibatch\n",
    "        z1,z2    (N,nz,1,1)\n",
    "    \"\"\"\n",
    "    return (1-alpha)*z1 + alpha*z2\n",
    "\n",
    "z1 = torch.tensor([[1,2],[3,4]]).view(2,2)\n",
    "z2 = torch.tensor([[1,2],[3,4]]).view(2,2)*10\n",
    "\n",
    "interpolate(z1,z2,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './figures/interpolate'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "z1 = torch.randn((batch_size, nz, 1, 1), device=device)\n",
    "z2 = torch.randn((batch_size, nz, 1, 1), device=device)\n",
    "\n",
    "for i, alpha in enumerate(np.linspace(-0.5,1.5,n_samples)):\n",
    "    z = interpolate(z1,z2,alpha)\n",
    "    x = G(z)\n",
    "    torchvision.utils.save_image(x, os.path.join(out_dir,f'{i}.png'), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector arithmetics\n",
    "\n",
    "z1 - z2 + z3\n",
    "\n",
    "+ z1: class=3, slanted\n",
    "+ z2: class=3, straight\n",
    "+ z3: class=6, arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "G, D = G.to(device), D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = torch.randn((64, nz, 1, 1)) + 1\n",
    "xx = G(zz)\n",
    "\n",
    "plot_one(torchvision.utils.make_grid(xx,normalize=True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = xx[[12,29,32,55,57]]\n",
    "z1 = zz[[12,29,32,55,57]]\n",
    "plot_one(torchvision.utils.make_grid(x1,normalize=True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzz = torch.randn((100,nz,1,1))\n",
    "xxx = G(zzz)\n",
    "plot_one(torchvision.utils.make_grid(xxx,normalize=True,nrow=10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = xxx[[32,89,49,88,38]]\n",
    "z2 = zzz[[12,29,32,55,57]]\n",
    "plot_one(torchvision.utils.make_grid(x2,normalize=True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = xxx[[0,1,27,44,77]]\n",
    "z3 = zzz[[0,1,27,44,77]]\n",
    "plot_one(torchvision.utils.make_grid(x3,normalize=True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zout = (z1-z2+z3).mean(0).unsqueeze(0)\n",
    "z1.mean(), z2.mean(), z3.mean(), zout.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xout = G(zout)\n",
    "plot_one(torchvision.utils.make_grid(xout,normalize=True)).show()\n",
    "\n",
    "xxout = G(z1-z2+z3)\n",
    "plot_one(torchvision.utils.make_grid(xxout,normalize=True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.cat((x1,x1.mean(0).unsqueeze(0),x2,x2.mean(0).unsqueeze(0),x3,x3.mean(0).unsqueeze(0),xxout,xout),dim=0)\n",
    "plot_one(torchvision.utils.make_grid(im,normalize=True,nrow=6)).show()\n",
    "torchvision.utils.save_image(im,'gifs/arithmetics.png',normalize=True,nrow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
