{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "#\n",
    "import os\n",
    "import itertools\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100\n",
    "nf = 128\n",
    "nc = 1\n",
    "data_root = '../data'\n",
    "figure_root = './figures'\n",
    "model_root = './models'\n",
    "image_size = 64\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "n_epochs = 10\n",
    "n_batches_print = 100\n",
    "\n",
    "load_weights_generator = ''\n",
    "load_weights_discriminator = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, nz, nf, nc):\n",
    "        \"\"\"\n",
    "            nz      dimension of noise \n",
    "            nf      dimension of features in last conv layer\n",
    "            nc      number of channels in the image\n",
    "\n",
    "            In DCGAN paper for LSUN dataset, nz=100, nf=128, nc=3\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_channels, out_channels, stride=2, padding=1, batch_norm=True, nonlinearity=nn.ReLU(True)):\n",
    "            \"\"\" stride=1, padding=0: H_out = H_in + 3       # 1 -> 4\n",
    "                stride=2, padding=1: H_out = 2 * H_in       # doubles\n",
    "            \"\"\"\n",
    "            return [\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=padding, bias=False),\n",
    "                *( [nn.BatchNorm2d(out_channels)] if batch_norm else [] ),\n",
    "                nonlinearity,\n",
    "            ]\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # (nz)   x 1 x 1\n",
    "            *block(nz,   8*nf, stride=1, padding=0),\n",
    "            # (8*nf) x 4 x 4\n",
    "            *block(8*nf, 4*nf),\n",
    "            # (4*nf) x 8 x 8\n",
    "            *block(4*nf, 2*nf),\n",
    "            # (2*nf) x 16 x 16\n",
    "            *block(2*nf,   nf),\n",
    "            # (nf) x 32 x 32\n",
    "            *block(nf,     nc, batch_norm=False, nonlinearity=nn.Tanh()),\n",
    "            # (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "            z       (N, nz, 1, 1)\n",
    "                noise vector\n",
    "            Returns (N, nc, h, w)\n",
    "                image generated from model distribution\n",
    "                \n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, nc, nf):\n",
    "        \"\"\"\n",
    "            nc      number of channels in the image\n",
    "            nf      dimension of features of first conv layer\n",
    "\n",
    "            In DCGAN paper for LSUN dataset, nc=3\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def block(in_channels, out_channels,\n",
    "                  stride=2, padding=1,\n",
    "                  batch_norm=True,\n",
    "                  nonlinearity=nn.LeakyReLU(0.2, inplace=True)):\n",
    "            \"\"\" stride=1, padding=0: H_out = H_in - 3              # 4 -> 1\n",
    "                stride=2, padding=1: H_out = floor((H_in-1)/2 +1)  # roughly halves\n",
    "            \"\"\"\n",
    "            return [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=padding, bias=False),\n",
    "                *( [nn.BatchNorm2d(out_channels)] if batch_norm else [] ),\n",
    "                nonlinearity,\n",
    "            ]\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # (nc) x 64 x 64\n",
    "            *block(nc,     nf, batch_norm=False),\n",
    "            # (nf) x 32 x 32\n",
    "            *block(nf,   2*nf),\n",
    "            # (2*nf) x 16 x 16\n",
    "            *block(2*nf, 4*nf),\n",
    "            # (4*nf) x 8 x 8\n",
    "            *block(4*nf, 8*nf),\n",
    "            # (8*nf) x 4 x 4\n",
    "            *block(8*nf, 1, stride=1, padding=0, batch_norm=False, nonlinearity=nn.Sigmoid()),\n",
    "            # 1 x 1 x 1\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x        (N, nc, h, w)\n",
    "            Returns  (N,)\n",
    "                classification probability that x comes from data distribution\n",
    "        \"\"\"\n",
    "        x = self.model(x)\n",
    "        return  x.view(-1, 1).squeeze(1)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# custom weights initialization called on G/D\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root=data_root, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(image_size),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,), (0.5,)),\n",
    "                   ]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(trainloader))\n",
    "\n",
    "im = x[0][0]\n",
    "plt.imshow(np.transpose(im,(1,2,0)).squeeze())\n",
    "\n",
    "torch.mean(x[0]), torch.std(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = Generator(nz, nf, nc).to(device)\n",
    "G.apply(weights_init)\n",
    "if load_weights_generator != '':\n",
    "    G.load_state_dict(torch.load(load_weights_generator))\n",
    "    \n",
    "    \n",
    "D = Discriminator(nc, nf).to(device)\n",
    "D.apply(weights_init)\n",
    "if load_weights_discriminator != '':\n",
    "    D.load_state_dict(torch.load(load_weights_discriminator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "os.makedirs(figure_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for it, (x_real, _) in enumerate(trainloader):\n",
    "        \n",
    "        # batch_size for last batch might be different ...\n",
    "        batch_size = x_real.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, device=device)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, device=device)\n",
    "        \n",
    "        ##############################################################\n",
    "        # Update Discriminator: Maximize E[log(D(x))] + E[log(1 - D(G(z)))]\n",
    "        ##############################################################\n",
    "        \n",
    "        D.zero_grad()\n",
    "        \n",
    "        # a minibatch of samples from data distribution\n",
    "        x_real = x_real.to(device)\n",
    "        \n",
    "        y = D(x_real)\n",
    "        loss_D_real = criterion(y, real_labels)\n",
    "        loss_D_real.backward()\n",
    "        \n",
    "        D_x = y.mean().item()\n",
    "        \n",
    "        \n",
    "        # a minibatch of samples from the model distribution\n",
    "        z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        \n",
    "        x_fake = G(z)\n",
    "        # https://github.com/pytorch/examples/issues/116\n",
    "        # If we do not detach, then, although x_fake is not needed for gradient update of D,\n",
    "        #   as a consequence of backward pass which clears all the variables in the graph\n",
    "        #   graph for G will not be available for gradient update of G\n",
    "        # Also for performance considerations, detaching x_fake will prevent computing \n",
    "        #   gradients for parameters in G\n",
    "        y = D(x_fake.detach())\n",
    "        loss_D_fake = criterion(y, fake_labels)\n",
    "        loss_D_fake.backward()\n",
    "        \n",
    "        D_G_z1 = y.mean().item()\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        \n",
    "        optimizerD.step()\n",
    "         \n",
    "        ##############################################################\n",
    "        # Update Generator: Minimize E[log(1 - D(G(z)))] => Maximize E[log(D(G(z))))]\n",
    "        ##############################################################\n",
    "        \n",
    "        G.zero_grad()\n",
    "        \n",
    "        y = D(x_fake)\n",
    "        loss_G = criterion(y, real_labels)\n",
    "        loss_G.backward()\n",
    "        \n",
    "        D_G_z2 = y.mean().item()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        \n",
    "        ##############################################################\n",
    "        # print\n",
    "        ##############################################################\n",
    "        \n",
    "        if it % n_batches_print == n_batches_print-1:\n",
    "            print(f\"[{epoch+1}/{n_epochs}][{it+1}/{len(trainloader)}] loss: {loss_D.item()+loss_G.item():.8} loss_D: {loss_D.item():.8}  loss_G: {loss_G.item():.8} D_x: {D_x:.8} D(G(z1)): {D_G_z1:.8} D(G(z2)): {D_G_z2:.8}\" ) \n",
    "\n",
    "\n",
    "            x_fake = G(fixed_noise)\n",
    "            vutils.save_image(x_fake.detach(), os.path.join(figure_root, f'dcgan_fake_samples_epoch={epoch}_it={it}.png'))\n",
    "    \n",
    "    # checkpointing\n",
    "    torch.save(G.state_dict(), os.path.join(model_root, f'G_epoch_{epoch}.pt'))\n",
    "    torch.save(D.state_dict(), os.path.join(model_root, f'D_epoch_{epoch}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up to date with 'origin/master'.\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[32mmodified:   dcgan.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "! git add dcgan.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='../figures/dcgan_fake_samples_epoch=6_it=599.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
