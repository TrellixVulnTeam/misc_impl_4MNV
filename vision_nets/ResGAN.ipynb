{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as tv_transforms\n",
    "import torchvision.utils as tv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "\n",
    "def apply_sn(module, use_sn):\n",
    "    if use_sn:\n",
    "        return spectral_norm(module)\n",
    "    else:\n",
    "        return module\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1, use_sn=False):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    module = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "    return apply_sn(module, use_sn)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, use_sn=False):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    module = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "    return apply_sn(module, use_sn)\n",
    "\n",
    "\n",
    "class UpsampleConv(nn.Module):\n",
    "    \"\"\" Upsample then Convolution. Better than ConvTranspose2d\n",
    "            https://distill.pub/2016/deconv-checkerboard/\n",
    "            https://github.com/pytorch/examples/blob/master/fast_neural_style/neural_style/transformer_net.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, scale_factor, use_sn=False):\n",
    "        super(UpsampleConv, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.pad  = torch.nn.ReflectionPad2d(kernel_size // 2)        \n",
    "        self.conv = apply_sn(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride), use_sn)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, mode='nearest', scale_factor=self.scale_factor)\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def deconv3x3(in_planes, out_planes, stride=1, dilation=1, use_sn=False):\n",
    "    return UpsampleConv(in_planes, out_planes, kernel_size=3, stride=1, scale_factor=2, use_sn=use_sn)\n",
    "\n",
    "\n",
    "def deconv1x1(in_planes, out_planes, stride=1, dilation=1, use_sn=False):\n",
    "    return UpsampleConv(in_planes, out_planes, kernel_size=1, stride=1, scale_factor=2, use_sn=use_sn)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\" Pre-activation Residual Block\n",
    "            BN, nonlinearity, conv3x3, BN, nonlinearity, conv3x3\n",
    "\n",
    "    References:\n",
    "        https://arxiv.org/abs/1512.03385\n",
    "        http://torch.ch/blog/2016/02/04/resnets.html\n",
    "\n",
    "        ResBlock\n",
    "            https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "        WGAN-GP resnet architecture\n",
    "            https://github.com/igul222/improved_wgan_training/blob/fa66c574a54c4916d27c55441d33753dcc78f6bc/gan_cifar_resnet.py#L159\n",
    "            Generator: BN, ReLU, conv3x3, Tanh -> out\n",
    "            PreactivationResblock: https://github.com/igul222/improved_wgan_training/blob/master/gan_64x64.py\n",
    "        SNGAN/Projection cGAN architecture\n",
    "            https://github.com/pfnet-research/sngan_projection/blob/master/dis_models/resblocks.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 resample=None,\n",
    "                 norm_layer=nn.Identity,\n",
    "                 nonlinearity=nn.ReLU(inplace=True),\n",
    "                 resblk_1st=False,\n",
    "                 use_sn=False):\n",
    "        \"\"\"\n",
    "            resample\n",
    "                \\in {None, 'up', 'dn'}\n",
    "            norm_layer\n",
    "                \\in {nn.Identity, nn.BatchNorm2d}\n",
    "            nonlinearity\n",
    "                either \n",
    "                    nn.ReLU(inplace=True)\n",
    "                    nn.LeakyReLU(slope=0.2)\n",
    "            resblk_1st\n",
    "                if True, no nonlinearity before first `conv_1`\n",
    "            use_sn\n",
    "                Apply spectral normalization for each linear/conv layers\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        if   resample == 'dn':\n",
    "            residual_conv_resample = conv3x3(in_channels, out_channels, 2, use_sn=use_sn)\n",
    "            shortcut_conv_resample = conv1x1(in_channels, out_channels, 2, use_sn=use_sn)\n",
    "        elif resample == 'up':\n",
    "            residual_conv_resample = deconv3x3(in_channels, out_channels, use_sn=use_sn)\n",
    "            shortcut_conv_resample = deconv1x1(in_channels, out_channels, use_sn=use_sn)\n",
    "        else:\n",
    "            residual_conv_resample = conv3x3(in_channels, out_channels, 1, use_sn=use_sn)\n",
    "            shortcut_conv_resample = conv1x1(in_channels, out_channels, 1, use_sn=use_sn)\n",
    "\n",
    "        self.residual = nn.Sequential()\n",
    "        self.residual.add_module('Normalization_1', norm_layer(in_channels))\n",
    "        self.residual.add_module('Nonlinearity_1', nn.Identity() if resblk_1st else nonlinearity)\n",
    "        self.residual.add_module('Conv_1', residual_conv_resample)\n",
    "        self.residual.add_module('Normalization_2', norm_layer(out_channels))\n",
    "        self.residual.add_module('Nonlinearity_2', nonlinearity)\n",
    "        self.residual.add_module('Conv_2', conv3x3(out_channels, out_channels, use_sn=use_sn))\n",
    "        \n",
    "        if in_channels == out_channels and resample == None:\n",
    "            self.shortcut = nn.Identity()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "            self.shortcut.add_module('Normalization_1', norm_layer(in_channels))\n",
    "            self.shortcut.add_module('Conv_1', shortcut_conv_resample)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.residual(x) + self.shortcut(x)\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_channels = None, conv_upsample = None, dim_z = 128, im_channnels = 3):\n",
    "        \"\"\"\n",
    "            conv_channels\n",
    "                [1024, 1024, 512, 256, 128, 64]\n",
    "                     c1    c2   c3   c4   c5\n",
    "            conv_upsample\n",
    "                4x4 -> 128x128    [True, True, True, True, True]\n",
    "                4x4 -> 64x64      [True, True, True, True]\n",
    "                4x4 -> 32x32      [True, True, True]\n",
    "            im_channnels\n",
    "                3 for color image\n",
    "                1 for grayscale image\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        n_convs = len(conv_channels) - 1\n",
    "        assert(n_convs > 0)\n",
    "        assert(n_convs == len(conv_upsample))\n",
    "        \n",
    "        self.bottom_width = 4\n",
    "        nonlinearity = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.Linear = nn.Linear(dim_z, (self.bottom_width**2) * conv_channels[0])\n",
    "        \n",
    "        self.ResidualBlocks = nn.Sequential()\n",
    "        for i in range(n_convs):\n",
    "            upsample = conv_upsample[i]\n",
    "            self.ResidualBlocks.add_module(f'ResBlock{\"Up\" if upsample else \"\"}_{i}',\n",
    "                  ResidualBlock(conv_channels[i], conv_channels[i+1],\n",
    "                                resample = \"up\" if upsample else None,\n",
    "                                norm_layer = nn.BatchNorm2d,\n",
    "                                nonlinearity = nonlinearity))\n",
    "        \n",
    "        self.NormalizationFinal = nn.BatchNorm2d(conv_channels[-1])\n",
    "        self.NonlinearityFinal = nonlinearity\n",
    "        self.ConvFinal = conv3x3(conv_channels[-1], im_channnels)\n",
    "        self.Tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 128\n",
    "        x = self.Linear(x)\n",
    "        x = x.view(x.shape[0], -1, self.bottom_width, self.bottom_width)\n",
    "        # 1024x4x4\n",
    "        x = self.ResidualBlocks(x)\n",
    "        # 64x128x128\n",
    "        x = self.NormalizationFinal(x)\n",
    "        x = self.NonlinearityFinal(x)\n",
    "        x = self.Tanh(self.ConvFinal(x))\n",
    "        # 3x128x128\n",
    "        return x\n",
    "\n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_channels = None, conv_dnsample = None, use_sn=True):\n",
    "        \"\"\"\n",
    "            conv_channels\n",
    "                [3, 64, 128, 256, 512, 1024, 1024]\n",
    "                  c1  c2   c3   c4   c5    c6\n",
    "            conv_dnsample\n",
    "                128x128 -> 4x4    [True, True, True, True, True, False]\n",
    "                64x64 -> 4x4      [True, True, True, True]\n",
    "                32x32 -> 4x4      [True, True, True]\n",
    "                \n",
    "        Projection cGAN \n",
    "            conv_channels = [3, 64, 128, 256, 512, 1024, 1024]\n",
    "            conv_dnsample = [True, True, True, True, True, False]\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        n_convs = len(conv_channels) - 1\n",
    "        assert(n_convs > 0)\n",
    "        assert(n_convs == len(conv_dnsample))\n",
    "        \n",
    "        nonlinearity = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        self.ResidualBlocks = nn.Sequential()\n",
    "        for i in range(n_convs):\n",
    "            downsample = conv_dnsample[i]\n",
    "            self.ResidualBlocks.add_module(f'ResBlock{\"Dn\" if downsample else \"\"}_{i}',\n",
    "                  ResidualBlock(conv_channels[i], conv_channels[i+1],\n",
    "                                resample = \"dn\" if downsample else None,\n",
    "                                norm_layer = nn.Identity,\n",
    "                                nonlinearity = nonlinearity,\n",
    "                                resblk_1st = True if i == 0 else False,\n",
    "                                use_sn = use_sn))\n",
    "        \n",
    "        self.NonlinearityFinal = nonlinearity\n",
    "        self.LinearFinal = apply_sn(nn.Linear(conv_channels[-1], 1), use_sn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3x128x128\n",
    "        x = self.ResidualBlocks(x)\n",
    "        # 1024x4x4\n",
    "        x = self.NonlinearityFinal(x)\n",
    "        x = torch.sum(x, dim=(2,3))   # (global sum pooling)\n",
    "        # 1024\n",
    "        x = self.LinearFinal(x)\n",
    "        # 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 28, 28]) torch.Size([32, 32, 28, 28])\n",
      "torch.Size([32, 50]) torch.Size([32, 1, 32, 32])\n",
      "torch.Size([50, 3, 32, 32]) torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "## resblock\n",
    "##############################\n",
    "\n",
    "blk = ResidualBlock(16, 32, resblk_1st=True)\n",
    "\n",
    "# print(blk)\n",
    "\n",
    "x = torch.empty((32, 16, 28, 28))\n",
    "out = blk(x)\n",
    "\n",
    "print(x.shape, out.shape)\n",
    "\n",
    "##############################\n",
    "## G\n",
    "##############################\n",
    "\n",
    "dim_z = 50\n",
    "conv_channels = [256, 256, 128, 64]\n",
    "conv_upsample = [True, True, True]\n",
    "G = Generator(conv_channels, conv_upsample, dim_z, im_channnels = 1)\n",
    "\n",
    "# print(G)\n",
    "\n",
    "x = torch.empty((32, dim_z))\n",
    "out = G(x)\n",
    "\n",
    "print(x.shape, out.shape)\n",
    "\n",
    "##############################\n",
    "## D\n",
    "##############################\n",
    "\n",
    "conv_channels = [3, 64, 128, 256]\n",
    "conv_dnsample = [True, True, True]\n",
    "D = Discriminator(conv_channels, conv_dnsample)\n",
    "\n",
    "# print(D)\n",
    "\n",
    "x = torch.empty((50, 3, 32, 32))\n",
    "out = D(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResGAN'\n",
    "seed = 0\n",
    "gpu_id = '2'\n",
    "image_size = 32\n",
    "dim_z = 50\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "n_epochs = 20\n",
    "figure_root = 'figures/'\n",
    "log_interval = 20\n",
    "use_sn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(figure_root, exist_ok=True)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(\n",
    "        root='./data', download=True, train=True, transform=tv_transforms.Compose([\n",
    "            tv_transforms.Resize(image_size),\n",
    "            tv_transforms.ToTensor(),\n",
    "            tv_transforms.Normalize((0.5,), (0.5,)),\n",
    "        ])),\n",
    "    batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_channels = [256, 256, 128, 64]\n",
    "conv_upsample = [True, True, True]\n",
    "G = Generator(conv_channels, conv_upsample, dim_z, im_channnels = 1).to(device)\n",
    "\n",
    "conv_channels = [1, 64, 128, 256]\n",
    "conv_dnsample = [True, True, True]\n",
    "D = Discriminator(conv_channels, conv_dnsample, use_sn=use_sn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "fixed_z = torch.randn(64, dim_z, device=device)\n",
    "\n",
    "# label flipping helps with training G!\n",
    "real_label = 0\n",
    "fake_label = 1\n",
    "\n",
    "optimizerD = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for it, (x_real, _) in enumerate(train_loader):\n",
    "\n",
    "        # batch_size for last batch might be different ...\n",
    "        batch_size = x_real.size(0)\n",
    "        real_labels = torch.full((batch_size, 1), real_label, device=device)\n",
    "        fake_labels = torch.full((batch_size, 1), fake_label, device=device)\n",
    "\n",
    "        ##############################################################\n",
    "        # Update Discriminator: Maximize E[log(D(x))] + E[log(1 - D(G(z)))]\n",
    "        ##############################################################\n",
    "\n",
    "        D.zero_grad()\n",
    "\n",
    "        # a minibatch of samples from data distribution\n",
    "        x_real = x_real.to(device)\n",
    "\n",
    "        y = D(x_real)\n",
    "        loss_D_real = criterion(y, real_labels)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        D_x = y.mean().item()\n",
    "\n",
    "        # a minibatch of samples from the model distribution\n",
    "        z = torch.randn(batch_size, dim_z, device=device)\n",
    "\n",
    "        x_fake = G(z)\n",
    "        # https://github.com/pytorch/examples/issues/116\n",
    "        # If we do not detach, then, although x_fake is not needed for gradient update of D,\n",
    "        #   as a consequence of backward pass which clears all the variables in the graph\n",
    "        #   graph for G will not be available for gradient update of G\n",
    "        # Also for performance considerations, detaching x_fake will prevent computing \n",
    "        #   gradients for parameters in G\n",
    "        y = D(x_fake.detach())\n",
    "        loss_D_fake = criterion(y, fake_labels)\n",
    "        loss_D_fake.backward()\n",
    "\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        ##############################################################\n",
    "        # Update Generator: Minimize E[log(1 - D(G(z)))] => Maximize E[log(D(G(z))))]\n",
    "        ##############################################################\n",
    "\n",
    "        G.zero_grad()\n",
    "\n",
    "        y = D(x_fake)\n",
    "        loss_G = criterion(y, real_labels)\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        ##############################################################\n",
    "        # write/print\n",
    "        ##############################################################\n",
    "        \n",
    "        loss_D = loss_D.item()\n",
    "        loss_G = loss_G.item()\n",
    "        loss_total = loss_D + loss_G\n",
    "        \n",
    "        global_step = epoch*len(train_loader)+it\n",
    "        \n",
    "        if it % log_interval == log_interval-1:\n",
    "            print(f'[{epoch+1}/{n_epochs}][{it+1}/{len(train_loader)}]'\n",
    "                f'loss: {loss_total:.4}\\t'\n",
    "                f'loss_D: {loss_D:.4}\\t'\n",
    "                f'loss_G: {loss_G:.4}')\n",
    "            x_fake = G(fixed_z)\n",
    "            tv_utils.save_image(x_fake.detach(),\n",
    "                os.path.join(figure_root,\n",
    "                    f'{model_name}_fake_samples_epoch={epoch}_it={it}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misc_impl] *",
   "language": "python",
   "name": "conda-env-misc_impl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
