
@article{junzhangFaceRecognitionEigenface1997,
	title = {Face recognition: eigenface, elastic matching, and neural nets},
	volume = {85},
	issn = {1558-2256},
	doi = {10.1109/5.628712},
	shorttitle = {Face recognition},
	abstract = {This paper is a comparative study of three recently proposed algorithms for face recognition: eigenface, autoassociation and classification neural nets, and elastic matching. After these algorithms were analyzed under a common statistical decision framework, they were evaluated experimentally on four individual data bases, each with a moderate subject size, and a combined data base with more than a hundred different subjects. Analysis and experimental results indicate that the eigenface algorithm, which is essentially a minimum distance classifier, works well when lighting variation is small. Its performance deteriorates significantly as lighting variation increases. The elastic matching algorithm, on the other hand, is insensitive to lighting, face position, and expression variations and therefore is more versatile. The performance of the autoassociation and classification nets is upper bounded by that of the eigenface but is more difficult to implement in practice.},
	pages = {1423--1435},
	number = {9},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Jun Zhang and Yong Yan and Lades, M.},
	date = {1997-09},
	file = {Jun Zhang et al_1997_Face recognition - eigenface, elastic matching, and neural nets.pdf:/Users/markwang/DropBox (MIT)/zotero/Jun Zhang et al_1997_Face recognition - eigenface, elastic matching, and neural nets.pdf:application/pdf}
}

@article{pentlandFaceRecognitionUsing1991,
	title = {Face Recognition Using Eigenfaces},
	abstract = {We present an approach t o the detection and identification of human faces and describe a working, near-real-time face recognition system which tracks a subject’s head and then recognizes the person by comparing characteristics of the face t o those of known individuals. Our approach treats face recognition as a two-dimensional recognition problem, taking advantage of the fact that faces are are normally upright and thus may be described by a small set of 2-D characteristic views. Face images are projected onto a feature space (“face space”) that best encodes the variation among known face images. T h e face space is defined by the “eigenfaces”, which are the eigenvectors of the set of faces; they do not necessarily correspond to isolated features such as eyes, ears, and noses. T h e framework provides the ability to learn t o recognize new faces in an unsupervised manner.},
	pages = {6},
	author = {Pentland, Alex P},
	date = {1991},
	langid = {english},
	file = {Pentland - Face Recognition Using Eigenfaces.pdf:/Users/markwang/Zotero/storage/2WTI2ATH/Pentland - Face Recognition Using Eigenfaces.pdf:application/pdf}
}

@article{turkEigenfacesRecognition1991,
	title = {Eigenfaces for Recognition},
	volume = {3},
	issn = {0898-929X, 1530-8898},
	url = {http://www.mitpressjournals.org/doi/10.1162/jocn.1991.3.1.71},
	doi = {10.1162/jocn.1991.3.1.71},
	pages = {71--86},
	number = {1},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Turk, Matthew and Pentland, Alex},
	urldate = {2020-02-04},
	date = {1991-01},
	langid = {english},
	file = {Turk and Pentland - 1991 - Eigenfaces for Recognition.pdf:/Users/markwang/Zotero/storage/CFHYMZAG/Turk and Pentland - 1991 - Eigenfaces for Recognition.pdf:application/pdf}
}


@article{shlensTutorialPrincipalComponent2014,
	title = {A Tutorial on Principal Component Analysis},
	url = {http://arxiv.org/abs/1404.1100},
	abstract = {Principal component analysis ({PCA}) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind {PCA}. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of {PCA} as well as the when, the how and the why of applying this technique.},
	journaltitle = {{arXiv}:1404.1100 [cs, stat]},
	author = {Shlens, Jonathon},
	urldate = {2020-01-31},
	date = {2014-04-03},
	eprinttype = {arxiv},
	eprint = {1404.1100},
	file = {Shlens_2014_A Tutorial on Principal Component Analysis.pdf:/Users/markwang/DropBox (MIT)/zotero/Shlens_2014_A Tutorial on Principal Component Analysis.pdf:application/pdf}
}